{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "\n",
    "Celem laboratorium jest zapoznanie się z podstawami sieci neuronowych oraz uczeniem głębokim (*deep learning*). Zapoznasz się na nim z następującymi tematami:\n",
    "- treningiem prostych sieci neuronowych, w szczególności z:\n",
    "  - regresją liniową w sieciach neuronowych\n",
    "  - optymalizacją funkcji kosztu\n",
    "  - algorytmem spadku wzdłuż gradientu\n",
    "  - siecią typu Multilayer Perceptron (MLP)\n",
    "- frameworkiem PyTorch, w szczególności z:\n",
    "  - ładowaniem danych\n",
    "  - preprocessingiem danych\n",
    "  - pisaniem pętli treningowej i walidacyjnej\n",
    "  - walidacją modeli\n",
    "- architekturą i hiperaprametrami sieci MLP, w szczególności z:\n",
    "  - warstwami gęstymi (w pełni połączonymi)\n",
    "  - funkcjami aktywacji\n",
    "  - regularyzacją: L2, dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystywane biblioteki\n",
    "\n",
    "Zaczniemy od pisania ręcznie prostych sieci w bibliotece Numpy, służącej do obliczeń numerycznych na CPU. Później przejdziemy do wykorzystywania frameworka PyTorch, służącego do obliczeń numerycznych na CPU, GPU oraz automatycznego różniczkowania, wykorzystywanego głównie do treningu sieci neuronowych.\n",
    "\n",
    "Wykorzystamy PyTorcha ze względu na popularność, łatwość instalacji i użycia, oraz dużą kontrolę nad niskopoziomowymi aspektami budowy i treningu sieci neuronowych. Framework ten został stworzony do zastosowań badawczych i naukowych, ale ze względu na wygodę użycia stał się bardzo popularny także w przemyśle. W szczególności całkowicie zdominował przetwarzanie języka naturalnego (NLP) oraz uczenie na grafach.\n",
    "\n",
    "Pierwszy duży framework do deep learningu, oraz obecnie najpopularniejszy, to TensorFlow, wraz z wysokopoziomową nakładką Keras. Są jednak szanse, że Google (autorzy) będzie go powoli porzucać na rzecz ich nowego frameworka JAX ([dyskusja](https://www.reddit.com/r/MachineLearning/comments/vfl57t/d_google_quietly_moving_its_products_from/), [artykuł Business Insidera](https://www.businessinsider.com/facebook-pytorch-beat-google-tensorflow-jax-meta-ai-2022-6?IR=T)), który jest bardzo świeżym, ale ciekawym narzędziem.\n",
    "\n",
    "Trzecia, ale znacznie mniej popularna od powyższych opcja to Apache MXNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja własnego komputera\n",
    "\n",
    "Jeżeli korzystasz z własnego komputera, to musisz zainstalować trochę więcej bibliotek (Google Colab ma je już zainstalowane).\n",
    "\n",
    "Jeżeli nie masz GPU lub nie chcesz z niego korzystać, to wystarczy znaleźć odpowiednią komendę CPU [na stronie PyTorcha](https://pytorch.org/get-started/locally/). Dla Anacondy odpowiednia komenda została podana poniżej, dla pip'a znajdź ją na stronie.\n",
    "\n",
    "Jeżeli chcesz korzystać ze wsparcia GPU (na tym laboratorium nie będzie potrzebne, na kolejnych może przyspieszyć nieco obliczenia), to musi być to odpowiednio nowa karta NVidii, mająca CUDA compatibility ([lista](https://developer.nvidia.com/cuda-gpus)). Poza PyTorchem będzie potrzebne narzędzie NVidia CUDA w wersji 11.6 lub 11.7. Instalacja na Windowsie jest bardzo prosta (wystarczy ściągnąć plik EXE i zainstalować jak każdy inny program). Instalacja na Linuxie jest trudna i można względnie łatwo zepsuć sobie system, ale jeżeli chcesz spróbować, to [ten tutorial](https://www.youtube.com/results?search_query=nvidia+cuda+install+ubuntu+20.04) jest bardzo dobry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# for conda users\n",
    "!conda install -y matplotlib pandas pytorch torchvision torchaudio -c pytorch -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Othm3C2lLAsj"
   },
   "source": [
    "## Wprowadzenie\n",
    "\n",
    "Zanim zaczniemy naszą przygodę z sieciami neuronowymi, przyjrzyjmy się prostemu przykładowi regresji liniowej na syntetycznych danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rnJsfxbnLAsj"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "EaYpEXzBLAsl",
    "outputId": "2f8d2922-72f0-4d38-8548-d1262adf522e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2d99c76be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = x + np.random.normal(scale=0.1, size=x.shape)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEM_-yKELAsl"
   },
   "source": [
    "W przeciwieństwie do laboratorium 1, tym razem będziemy chcieli rozwiązać ten problem własnoręcznie, bez użycia wysokopoziomowego interfejsu Scikit-learn'a. W tym celu musimy sobie przypomnieć sformułowanie naszego **problemu optymalizacyjnego (optimization problem)**.\n",
    "\n",
    "W przypadku prostej regresji liniowej (1 zmienna) mamy model postaci $\\hat{y} = \\alpha x + \\beta$, z dwoma parametrami, których będziemy się uczyć. Miarą niedopasowania modelu o danych parametrach jest **funkcja kosztu (cost function)**, nazywana też funkcją celu. Najczęściej używa się **błędu średniokwadratowego (mean squared error, MSE)**:\n",
    "$$\\large\n",
    "MSE = \\frac{1}{N} \\sum_{i}^{N} (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "Od jakich $\\alpha$ i $\\beta$ zacząć? W najprostszym wypadku wystarczy po prostu je wylosować jako niewielkie liczby zmiennoprzecinkowe.\n",
    "\n",
    "#### Zadanie 1 (0.5 punkt)\n",
    "\n",
    "Uzupełnij kod funkcji `mse`, obliczającej błąd średniokwadratowy. Wykorzystaj Numpy'a w celu wektoryzacji obliczeń dla wydajności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaA7Q46TLAsm",
    "outputId": "5c57fe58-1934-4d21-9a7b-d14e9a23140b"
   },
   "outputs": [],
   "source": [
    "def mse(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    return 1 / y.size * np.square(y - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "qSGfamGbLAsm",
    "outputId": "733ce15f-ae75-466b-e7ee-eb3c9d9d534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [1.84889663e-03 3.14225100e-03 2.46889857e-03 1.33111842e-03\n",
      " 1.57100323e-03 4.55655743e-03 2.27020322e-03 3.37318666e-03\n",
      " 3.25080067e-03 2.63124422e-03 2.84934323e-03 1.57569110e-03\n",
      " 2.12017601e-03 2.68915171e-03 2.30910856e-03 2.35934694e-03\n",
      " 1.32402084e-03 2.78757663e-03 2.21212958e-03 3.37827749e-03\n",
      " 5.55471011e-03 1.75409178e-03 1.53599235e-03 2.98944156e-03\n",
      " 5.74782636e-04 3.67646537e-03 2.02956167e-03 2.19006364e-03\n",
      " 8.41958464e-04 8.44992831e-04 1.73313260e-03 1.50674347e-03\n",
      " 2.59023097e-03 3.75063822e-03 1.96529489e-03 1.49823733e-03\n",
      " 7.49975967e-04 7.33479834e-04 1.79758488e-03 1.67819100e-03\n",
      " 2.28926528e-03 2.59885358e-03 2.83657543e-03 2.59438341e-04\n",
      " 1.61036882e-03 1.50789763e-03 2.15267266e-03 6.50866317e-04\n",
      " 2.38573626e-03 1.17309394e-03 1.63990635e-03 7.33873625e-04\n",
      " 1.25920039e-03 1.73068643e-03 8.69958295e-04 5.92822662e-04\n",
      " 7.49890671e-04 5.97441691e-04 1.10413957e-03 8.95854095e-04\n",
      " 1.05274616e-03 8.25700948e-04 1.06856936e-03 1.70060380e-03\n",
      " 4.67395246e-04 7.19818418e-04 1.48468739e-03 2.89676003e-04\n",
      " 9.08341987e-04 3.98573683e-04 1.59034647e-04 3.25081112e-04\n",
      " 5.39323319e-05 9.30504022e-04 1.83616722e-04 5.68349296e-04\n",
      " 6.30913095e-04 4.67274977e-04 3.37148653e-04 1.98879513e-04\n",
      " 6.62220847e-04 2.01773826e-05 6.82540350e-05 7.67217798e-04\n",
      " 9.78580234e-06 6.06305342e-05 1.43383783e-06 1.39420594e-04\n",
      " 4.05376468e-04 2.89015309e-06 1.51149250e-04 2.06470968e-05\n",
      " 2.51585372e-05 1.05610474e-05 5.62157122e-06 2.93453011e-06\n",
      " 2.17689418e-05 1.86867519e-04 5.46470074e-06 9.90159063e-07]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2d97b1e490>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.rand()\n",
    "b = np.random.rand()\n",
    "print(f\"MSE: {mse(y, a * x + b)}\")\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, a * x + b, color=\"g\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y--E9Mp9LAsn"
   },
   "source": [
    "Losowe parametry radzą sobie nie najlepiej. Jak lepiej dopasować naszą prostą do danych? Zawsze możemy starać się wyprowadzić rozwiązanie analitycznie, i w tym wypadku nawet nam się uda. Jest to jednak szczególny i dość rzadki przypadek, a w szczególności nie będzie to możliwe w większych sieciach neuronowych.\n",
    "\n",
    "Potrzebna nam będzie **metoda optymalizacji (optimization method)**, dającą wartości parametrów minimalizujące dowolną różniczkowalną funkcję kosztu. Zdecydowanie najpopularniejszy jest tutaj **spadek wzdłuż gradientu (gradient descent)**.\n",
    "\n",
    "Metoda ta wywodzi się z prostych obserwacji, które tutaj przedstawimy. Bardziej szczegółowe rozwinięcie dla zainteresowanych: [sekcja 4.3 \"Deep Learning Book\"](https://www.deeplearningbook.org/contents/numerical.html), [ten praktyczny kurs](https://cs231n.github.io/optimization-1/), [analiza oryginalnej publikacji Cauchy'ego](https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf) (oryginał w języku francuskim).\n",
    "\n",
    "Pochodna jest dokładnie równa granicy funkcji. Dla małego $\\epsilon$ można ją przybliżyć jako:\n",
    "$$\\large\n",
    "\\frac{f(x)}{dx} \\approx \\frac{f(x) - f(x+\\epsilon)}{\\epsilon}\n",
    "$$\n",
    "\n",
    "Przyglądając się temu równaniu widzimy, że: \n",
    "* dla funkcji rosnącej ($f(x+\\epsilon) > f(x)$) wyrażenie $\\frac{f(x)}{dx}$ będzie miało znak ujemny \n",
    "* dla funkcji malejącej ($f(x+\\epsilon) < f(x)$) wyrażenie $\\frac{f(x)}{dx}$ będzie miało znak dodatni \n",
    "\n",
    "Widzimy więc, że potrafimy wskazać kierunek zmniejszenia wartości funkcji, patrząc na znak pochodnej. Zaobserwowano także, że amplituda wartości w $\\frac{f(x)}{dx}$ jest tym większa, im dalej jesteśmy od minimum (maximum). Pochodna wyznacza więc, w jakim kierunku funkcja najszybciej rośnie, więc kierunek o przeciwnym zwrocie to kierunek, w którym funkcja najszybciej spada.\n",
    "\n",
    "Stosując powyższe do optymalizacji, mamy:\n",
    "$$\\large\n",
    "x_{t+1} = x_{t} -  \\alpha * \\frac{f(x)}{dx}\n",
    "$$\n",
    "\n",
    "$\\alpha$ to niewielka wartość (rzędu zwykle $10^{-5}$ - $10^{-2}$), wprowadzona, aby trzymać się założenia o małej zmianie parametrów ($\\epsilon$). Nazywa się ją **stałą uczącą (learning rate)** i jest zwykle najważniejszym hiperparametrem podczas nauki sieci.\n",
    "\n",
    "Metoda ta zakłada, że używamy całego zbioru danych do aktualizacji parametrów w każdym kroku, co nazywa się po prostu GD (od *gradient descent*) albo *full batch GD*. Wtedy każdy krok optymalizacji nazywa się **epoką (epoch)**.\n",
    "\n",
    "Im większa stała ucząca, tym większe nasze kroki podczas minimalizacji. Możemy więc uczyć szybciej, ale istnieje ryzyko, że będziemy \"przeskakiwać\" minima. Mniejsza stała ucząca to wolniejszy trening, ale dokładniejszy. Można także zmieniać ją podczas treningu, co nazywa się **learning rate scheduling (LR scheduling)**. Obrazowo:\n",
    "\n",
    "![learning_rate](http://www.bdhammel.com/assets/learning-rate/lr-types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "496qEjkVLAso"
   },
   "source": [
    "![interactive LR](http://cdn-images-1.medium.com/max/640/1*eeIvlwkMNG1wSmj3FR6M2g.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYkyAHKzLAsp"
   },
   "source": [
    "Policzmy więc pochodną dla naszej funkcji kosztu MSE. Pochodną liczymy po predykcjach naszego modelu, czyli de facto po jego parametrach, bo to od nich zależą predykcje.\n",
    "$$\\large\n",
    "\\frac{\\text{d} MSE}{\\text{d} \\hat{y}} = -2 \\cdot \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i) = -2 \\cdot \\frac{1}{N} \\sum_{i=1}^{N} (y_i - (ax + b))\n",
    "$$\n",
    "\n",
    "Musimy jeszcze się dowiedzieć, jak zaktualizować każdy z naszych parametrów. Możemy wykorzystać tutaj regułę łańcuchową (*chain rule*) i policzyć ponownie pochodną, tylko że po naszych parametrach. Dzięki temu dostajemy informację, jak każdy z parametrów wpływa na funkcję kosztu i jak zmodyfikować każdy z nich w kolejnym kroku.\n",
    "$$\\large\n",
    "\\frac{\\text{d} \\hat{y}}{\\text{d} a} = x\n",
    "$$\n",
    "\n",
    "$$\\large\n",
    "\\frac{\\text{d} \\hat{y}}{\\text{d} b} = 1\n",
    "$$\n",
    "\n",
    "Pełna aktualizacja to zatem:\n",
    "$$\\large\n",
    "a' = a + \\alpha * \\left( \\frac{-2}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i) * (-x) \\right)\n",
    "$$\n",
    "$$\\large\n",
    "b' = b + \\alpha * \\left( \\frac{-2}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i) * (-1) \\right)\n",
    "$$\n",
    "\n",
    "Liczymy więc pochodną funkcji kosztu, a potem za pomocą reguły łańcuchowej \"cofamy się\", dochodząc do tego, jak każdy z parametrów wpływa na błąd i w jaki sposób powinniśmy go zmienić. Nazywa się to **propagacją wsteczną (backpropagation)** i jest podstawowym mechanizmem umożliwiającym naukę sieci neuronowych za pomocą spadku wzdłuż gradientu. Więcej możesz o tym przeczytać [tutaj](https://cs231n.github.io/optimization-2/).\n",
    "\n",
    "Obliczenie pochodnych cząstkowych ze względu na każdy \n",
    "\n",
    "\n",
    "#### Zadanie 2 (1.5 punkty)\n",
    "\n",
    "Zaimplementuj funkcję realizującą jedną epokę treningową. Oblicz predykcję przy aktualnych parametrach oraz zaktualizuj je zgodnie z powyższymi wzorami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qbdWOSULAsp",
    "outputId": "055607ae-87aa-470a-e6da-25682c82d470"
   },
   "outputs": [],
   "source": [
    "def optimize(\n",
    "    x: np.ndarray, y: np.ndarray, a: float, b: float, learning_rate: float = 0.1\n",
    "):\n",
    "    y_hat = a * x + b\n",
    "    errors = y - y_hat\n",
    "\n",
    "    new_a = a + learning_rate * -2 / y.size * errors * -x\n",
    "    new_b = b + learning_rate * -2 / y.size * errors * -1\n",
    "\n",
    "    return new_a, new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss:  [1.84889663e-03 3.14225100e-03 2.46889857e-03 1.33111842e-03\n",
      " 1.57100323e-03 4.55655743e-03 2.27020322e-03 3.37318666e-03\n",
      " 3.25080067e-03 2.63124422e-03 2.84934323e-03 1.57569110e-03\n",
      " 2.12017601e-03 2.68915171e-03 2.30910856e-03 2.35934694e-03\n",
      " 1.32402084e-03 2.78757663e-03 2.21212958e-03 3.37827749e-03\n",
      " 5.55471011e-03 1.75409178e-03 1.53599235e-03 2.98944156e-03\n",
      " 5.74782636e-04 3.67646537e-03 2.02956167e-03 2.19006364e-03\n",
      " 8.41958464e-04 8.44992831e-04 1.73313260e-03 1.50674347e-03\n",
      " 2.59023097e-03 3.75063822e-03 1.96529489e-03 1.49823733e-03\n",
      " 7.49975967e-04 7.33479834e-04 1.79758488e-03 1.67819100e-03\n",
      " 2.28926528e-03 2.59885358e-03 2.83657543e-03 2.59438341e-04\n",
      " 1.61036882e-03 1.50789763e-03 2.15267266e-03 6.50866317e-04\n",
      " 2.38573626e-03 1.17309394e-03 1.63990635e-03 7.33873625e-04\n",
      " 1.25920039e-03 1.73068643e-03 8.69958295e-04 5.92822662e-04\n",
      " 7.49890671e-04 5.97441691e-04 1.10413957e-03 8.95854095e-04\n",
      " 1.05274616e-03 8.25700948e-04 1.06856936e-03 1.70060380e-03\n",
      " 4.67395246e-04 7.19818418e-04 1.48468739e-03 2.89676003e-04\n",
      " 9.08341987e-04 3.98573683e-04 1.59034647e-04 3.25081112e-04\n",
      " 5.39323319e-05 9.30504022e-04 1.83616722e-04 5.68349296e-04\n",
      " 6.30913095e-04 4.67274977e-04 3.37148653e-04 1.98879513e-04\n",
      " 6.62220847e-04 2.01773826e-05 6.82540350e-05 7.67217798e-04\n",
      " 9.78580234e-06 6.06305342e-05 1.43383783e-06 1.39420594e-04\n",
      " 4.05376468e-04 2.89015309e-06 1.51149250e-04 2.06470968e-05\n",
      " 2.51585372e-05 1.05610474e-05 5.62157122e-06 2.93453011e-06\n",
      " 2.17689418e-05 1.86867519e-04 5.46470074e-06 9.90159063e-07]\n",
      "step 100 loss:  [1.23885617e-03 2.10538426e-03 1.65401889e-03 8.91589840e-04\n",
      " 1.05196472e-03 3.05000888e-03 1.51891556e-03 2.25568466e-03\n",
      " 2.17251083e-03 1.75723904e-03 1.90141539e-03 1.05058296e-03\n",
      " 1.41228613e-03 1.78946030e-03 1.53486992e-03 1.56640467e-03\n",
      " 8.77922934e-04 1.84587495e-03 1.46273073e-03 2.23044734e-03\n",
      " 3.66155329e-03 1.15432486e-03 1.00902293e-03 1.96021076e-03\n",
      " 3.76167720e-04 2.40125353e-03 1.32282961e-03 1.42435084e-03\n",
      " 5.46353784e-04 5.47045970e-04 1.11932077e-03 9.70685457e-04\n",
      " 1.66440338e-03 2.40364663e-03 1.25603857e-03 9.54838948e-04\n",
      " 4.76579736e-04 4.64707379e-04 1.13539875e-03 1.05665317e-03\n",
      " 1.43675826e-03 1.62566235e-03 1.76835019e-03 1.61175095e-04\n",
      " 9.96881212e-04 9.30055004e-04 1.32281139e-03 3.98436682e-04\n",
      " 1.45479557e-03 7.12506412e-04 9.92009681e-04 4.42102983e-04\n",
      " 7.55382192e-04 1.03377120e-03 5.17372138e-04 3.50988092e-04\n",
      " 4.41970143e-04 3.50495393e-04 6.44713820e-04 5.20596100e-04\n",
      " 6.08796745e-04 4.75139204e-04 6.11807261e-04 9.68708876e-04\n",
      " 2.64860406e-04 4.05753908e-04 8.32427027e-04 1.61532328e-04\n",
      " 5.03728453e-04 2.19796238e-04 8.72031755e-05 1.77225242e-04\n",
      " 2.92307999e-05 5.01339337e-04 9.83359117e-05 3.02528292e-04\n",
      " 3.33760793e-04 2.45650563e-04 1.76120732e-04 1.03225563e-04\n",
      " 3.41485732e-04 1.03364495e-05 3.47325019e-05 3.87785816e-04\n",
      " 4.91246572e-06 3.02265553e-05 7.09832349e-07 6.85339069e-05\n",
      " 1.97844609e-04 1.40035443e-06 7.27007445e-05 9.85761609e-06\n",
      " 1.19218221e-05 4.96675662e-06 2.62359343e-06 1.35898481e-06\n",
      " 1.00026449e-05 8.51877465e-05 2.47138125e-06 4.44193963e-07]\n",
      "step 200 loss:  [8.30097574e-04 1.41065843e-03 1.10809676e-03 5.97191377e-04\n",
      " 7.04409609e-04 2.04157510e-03 1.01625460e-03 1.50839956e-03\n",
      " 1.45188948e-03 1.17354711e-03 1.26884696e-03 7.00470129e-04\n",
      " 9.40748360e-04 1.19077259e-03 1.02023167e-03 1.03995879e-03\n",
      " 5.82127302e-04 1.22229979e-03 9.67204273e-04 1.47261299e-03\n",
      " 2.41362235e-03 7.59632938e-04 6.62846581e-04 1.28533244e-03\n",
      " 2.46183766e-04 1.56835927e-03 8.62195129e-04 9.26354500e-04\n",
      " 3.54533472e-04 3.54156015e-04 7.22898519e-04 6.25342186e-04\n",
      " 1.06949482e-03 1.54040907e-03 8.02746143e-04 6.08526699e-04\n",
      " 3.02847364e-04 2.94422475e-04 7.17145735e-04 6.65309201e-04\n",
      " 9.01719133e-04 1.01690150e-03 1.10240763e-03 1.00129423e-04\n",
      " 6.17108415e-04 5.73647902e-04 8.12863933e-04 2.43908442e-04\n",
      " 8.87118234e-04 4.32757660e-04 6.00085004e-04 2.66333386e-04\n",
      " 4.53146504e-04 6.17490763e-04 3.07685932e-04 2.07806902e-04\n",
      " 2.60488114e-04 2.05621774e-04 3.76452325e-04 3.02527276e-04\n",
      " 3.52063478e-04 2.73412867e-04 3.50289030e-04 5.51802180e-04\n",
      " 1.50089320e-04 2.28719118e-04 4.66720980e-04 9.00754380e-05\n",
      " 2.79346720e-04 1.21208168e-04 4.78159569e-05 9.66183062e-05\n",
      " 1.58428095e-05 2.70112891e-04 5.26637848e-05 1.61033660e-04\n",
      " 1.76563568e-04 1.29140660e-04 9.20024796e-05 5.35777499e-05\n",
      " 1.76093075e-04 5.29514606e-06 1.76743645e-05 1.96004107e-04\n",
      " 2.46605425e-06 1.50690516e-05 3.51407916e-07 3.36886845e-05\n",
      " 9.65583658e-05 6.78508182e-07 3.49680746e-05 4.70635634e-06\n",
      " 5.64936828e-06 2.33581675e-06 1.22443392e-06 6.29347684e-07\n",
      " 4.59613085e-06 3.88347435e-05 1.11766875e-06 1.99269273e-07]\n",
      "step 300 loss:  [5.56208219e-04 9.45175304e-04 7.42360578e-04 4.00001800e-04\n",
      " 4.71682071e-04 1.36656287e-03 6.79941297e-04 1.00868232e-03\n",
      " 9.70298069e-04 7.83736751e-04 8.46723241e-04 4.67034420e-04\n",
      " 6.26648851e-04 7.92383809e-04 6.78150404e-04 6.90443734e-04\n",
      " 3.85993101e-04 8.09381358e-04 6.39546354e-04 9.72266413e-04\n",
      " 1.59101136e-03 4.99895842e-04 4.35436674e-04 8.42807069e-04\n",
      " 1.61115490e-04 1.02436113e-03 5.61962352e-04 6.02472816e-04\n",
      " 2.30059691e-04 2.29279603e-04 4.66874449e-04 4.02862582e-04\n",
      " 6.87224731e-04 9.87191737e-04 5.13042660e-04 3.87819060e-04\n",
      " 1.92447389e-04 1.86535867e-04 4.52966857e-04 4.18904090e-04\n",
      " 5.65924983e-04 6.36102970e-04 6.87252212e-04 6.22050281e-05\n",
      " 3.82014218e-04 3.53819843e-04 4.99502636e-04 1.49311875e-04\n",
      " 5.40954880e-04 2.62845624e-04 3.63002518e-04 1.60445587e-04\n",
      " 2.71838225e-04 3.68838718e-04 1.82983632e-04 1.23034682e-04\n",
      " 1.53526339e-04 1.20630156e-04 2.19812805e-04 1.75803762e-04\n",
      " 2.03596182e-04 1.57331988e-04 2.00557287e-04 3.14321106e-04\n",
      " 8.50516100e-05 1.28926509e-04 2.61678761e-04 5.02288591e-05\n",
      " 1.54914001e-04 6.68410899e-05 2.62188357e-05 5.26736315e-05\n",
      " 8.58664884e-06 1.45532114e-04 2.82040831e-05 8.57170733e-05\n",
      " 9.34043007e-05 6.78903804e-05 4.80605331e-05 2.78087637e-05\n",
      " 9.08054659e-05 2.71259216e-06 8.99397227e-06 9.90691467e-05\n",
      " 1.23795746e-06 7.51247746e-06 1.73967168e-07 1.65600870e-05\n",
      " 4.71254590e-05 3.28754881e-07 1.68191709e-05 2.24697227e-06\n",
      " 2.67705403e-06 1.09851162e-06 5.71444650e-07 2.91451753e-07\n",
      " 2.11188331e-06 1.77036882e-05 5.05459627e-07 8.93939280e-08]\n",
      "step 400 loss:  [3.72688215e-04 6.33290340e-04 4.97338544e-04 2.67923225e-04\n",
      " 3.15844607e-04 9.14732000e-04 4.54925534e-04 6.74516259e-04\n",
      " 6.48450421e-04 5.23407446e-04 5.65032877e-04 3.11392507e-04\n",
      " 4.17421702e-04 5.27281283e-04 4.50768178e-04 4.58395615e-04\n",
      " 2.55941739e-04 5.35955409e-04 4.22888475e-04 6.41921524e-04\n",
      " 1.04876272e-03 3.28969217e-04 2.86046731e-04 5.52638160e-04\n",
      " 1.05442375e-04 6.69053166e-04 3.66276350e-04 3.91830011e-04\n",
      " 1.49287629e-04 1.48434967e-04 3.01524689e-04 2.59535121e-04\n",
      " 4.41589640e-04 6.32655018e-04 3.27890422e-04 2.47160270e-04\n",
      " 1.22292620e-04 1.18182655e-04 2.86104990e-04 2.63758018e-04\n",
      " 3.55178319e-04 3.97901852e-04 4.28440072e-04 3.86446402e-05\n",
      " 2.36481725e-04 2.18232266e-04 3.06942986e-04 9.14032983e-05\n",
      " 3.29868298e-04 1.59645520e-04 2.19586937e-04 9.66562503e-05\n",
      " 1.63073134e-04 2.20314226e-04 1.08822036e-04 7.28442267e-05\n",
      " 9.04852673e-05 7.07689378e-05 1.28350035e-04 1.02162566e-04\n",
      " 1.17738442e-04 9.05347096e-05 1.14828676e-04 1.79045610e-04\n",
      " 4.81964764e-05 7.26744881e-05 1.46716726e-04 2.80091704e-05\n",
      " 8.59088217e-05 3.68599852e-05 1.43765260e-05 2.87162088e-05\n",
      " 4.65388024e-06 7.84101648e-05 1.51046930e-05 4.56265891e-05\n",
      " 4.94120248e-05 3.56905698e-05 2.51060064e-05 1.44337405e-05\n",
      " 4.68254226e-05 1.38960401e-06 4.57677204e-06 5.00739295e-05\n",
      " 6.21453752e-07 3.74524682e-06 8.61237729e-08 8.14031436e-06\n",
      " 2.29996527e-05 1.59290300e-07 8.08979366e-06 1.07277988e-06\n",
      " 1.26856986e-06 5.16619203e-07 2.66693843e-07 1.34971697e-07\n",
      " 9.70392544e-07 8.07062304e-06 2.28591373e-07 4.01028932e-08]\n",
      "step 500 loss:  [2.49720340e-04 4.24319862e-04 3.33187988e-04 1.79456329e-04\n",
      " 2.11493762e-04 6.12291356e-04 3.04375161e-04 4.51055970e-04\n",
      " 4.33359564e-04 3.49550221e-04 3.77056087e-04 2.07619159e-04\n",
      " 2.78051858e-04 3.50872328e-04 2.99626674e-04 3.04335501e-04\n",
      " 1.69708147e-04 3.54898464e-04 2.79627365e-04 4.23817214e-04\n",
      " 6.91323309e-04 2.16486589e-04 1.87909602e-04 3.62371113e-04\n",
      " 6.90069871e-05 4.36986648e-04 2.38731944e-04 2.54834332e-04\n",
      " 9.68739723e-05 9.60963781e-05 1.94735733e-04 1.67199641e-04\n",
      " 2.83752027e-04 4.05445424e-04 2.09557873e-04 1.57517269e-04\n",
      " 7.77120695e-05 7.48764305e-05 1.80710938e-04 1.66072124e-04\n",
      " 2.22912298e-04 2.48899772e-04 2.67093931e-04 2.40078376e-05\n",
      " 1.46391426e-04 1.34603309e-04 1.88615615e-04 5.59537741e-05\n",
      " 2.01150037e-04 9.69644913e-05 1.32832200e-04 5.82280316e-05\n",
      " 9.78260027e-05 1.31597785e-04 6.47174580e-05 4.31283380e-05\n",
      " 5.33301560e-05 4.15173347e-05 7.49443671e-05 5.93684102e-05\n",
      " 6.80874294e-05 5.20970576e-05 6.57449297e-05 1.01989112e-04\n",
      " 2.73116563e-05 4.09658281e-05 8.22603927e-05 1.56187825e-05\n",
      " 4.76414374e-05 2.03266960e-05 7.88305406e-06 1.56552837e-05\n",
      " 2.52235787e-06 4.22460292e-05 8.08931640e-06 2.42867092e-05\n",
      " 2.61395693e-05 1.87628463e-05 1.31149514e-05 7.49162627e-06\n",
      " 2.41463460e-05 7.11864962e-07 2.32898676e-06 2.53095792e-05\n",
      " 3.11969336e-07 1.86714354e-06 4.26362304e-08 4.00147160e-06\n",
      " 1.12250159e-05 7.71802980e-08 3.89108131e-06 5.12181074e-07\n",
      " 6.01134478e-07 2.42960926e-07 1.24466308e-07 6.25055730e-08\n",
      " 4.45887179e-07 3.67917439e-06 1.03379207e-07 1.79905065e-08]\n",
      "step 600 loss:  [1.67325517e-04 2.84304581e-04 2.23216633e-04 1.20200755e-04\n",
      " 1.41619044e-04 4.09847588e-04 2.03647040e-04 3.01625773e-04\n",
      " 2.89614295e-04 2.33442145e-04 2.51615965e-04 1.38428877e-04\n",
      " 1.85215181e-04 2.33483331e-04 1.99162559e-04 2.02052756e-04\n",
      " 1.12528950e-04 2.35006341e-04 1.84898544e-04 2.79817742e-04\n",
      " 4.55706434e-04 1.42464525e-04 1.23441433e-04 2.37610852e-04\n",
      " 4.51617697e-05 2.85414285e-04 1.55600931e-04 1.65736505e-04\n",
      " 6.28623187e-05 6.22125235e-05 1.25767498e-04 1.07714593e-04\n",
      " 1.82330393e-04 2.59835118e-04 1.33930421e-04 1.00387048e-04\n",
      " 4.93829125e-05 4.74391090e-05 1.14141466e-04 1.04565354e-04\n",
      " 1.39901255e-04 1.55694416e-04 1.66509093e-04 1.49147790e-05\n",
      " 9.06220119e-05 8.30218704e-05 1.15903773e-04 3.42528650e-05\n",
      " 1.22659066e-04 5.88936824e-05 8.03526544e-05 3.50779557e-05\n",
      " 5.86848771e-05 7.86058047e-05 3.84880629e-05 2.55346734e-05\n",
      " 3.14316974e-05 2.43565770e-05 4.37604723e-05 3.44999961e-05\n",
      " 3.93745490e-05 2.99785952e-05 3.76421287e-05 5.80956938e-05\n",
      " 1.54767863e-05 2.30919971e-05 4.61213414e-05 8.70951774e-06\n",
      " 2.64199474e-05 1.12092983e-05 4.32250054e-06 8.53482822e-06\n",
      " 1.36709346e-06 2.27614237e-05 4.33223235e-06 1.29276427e-05\n",
      " 1.38281539e-05 9.86379323e-06 6.85102794e-06 3.88842131e-06\n",
      " 1.24514845e-05 3.64673475e-07 1.18515392e-06 1.27925810e-05\n",
      " 1.56608382e-07 9.30839853e-07 2.11073909e-08 1.96697256e-06\n",
      " 5.47838628e-06 3.73958640e-08 1.87155747e-06 2.44532413e-07\n",
      " 2.84858306e-07 1.14262132e-07 5.80885620e-08 2.89464144e-08\n",
      " 2.04881393e-07 1.67723410e-06 4.67526854e-08 8.07069760e-09]\n",
      "step 700 loss:  [1.12116732e-04 1.90490953e-04 1.49542202e-04 8.05110729e-05\n",
      " 9.48300011e-05 2.74338424e-04 1.36253290e-04 2.01700261e-04\n",
      " 1.93549299e-04 1.55901017e-04 1.67907630e-04 9.22966556e-05\n",
      " 1.23375054e-04 1.55368382e-04 1.32383824e-04 1.34145757e-04\n",
      " 7.46149477e-05 1.55616284e-04 1.22260823e-04 1.84744664e-04\n",
      " 3.00392524e-04 9.37524168e-05 8.10910531e-05 1.55804132e-04\n",
      " 2.95562164e-05 1.86416025e-04 1.01417721e-04 1.07789986e-04\n",
      " 4.07918765e-05 4.02762119e-05 8.12252754e-05 6.93926941e-05\n",
      " 1.17159946e-04 1.66518808e-04 8.55961998e-05 6.39774898e-05\n",
      " 3.13808661e-05 3.00557739e-05 7.20945529e-05 6.58383415e-05\n",
      " 8.78029670e-05 9.73916162e-05 1.03803475e-04 9.26575046e-06\n",
      " 5.60985657e-05 5.12069949e-05 7.12225476e-05 2.09683579e-05\n",
      " 7.47961411e-05 3.57704741e-05 4.86068068e-05 2.11317975e-05\n",
      " 3.52044928e-05 4.69527091e-05 2.28892023e-05 1.51181236e-05\n",
      " 1.85251962e-05 1.42890396e-05 2.55520063e-05 2.00485364e-05\n",
      " 2.27700637e-05 1.72508048e-05 2.15519259e-05 3.30928427e-05\n",
      " 8.77028157e-06 1.30167107e-05 2.58590807e-05 4.85669734e-06\n",
      " 1.46513972e-05 6.18144571e-06 2.37014877e-06 4.65295257e-06\n",
      " 7.40951373e-07 1.22634581e-05 2.32012647e-06 6.88129238e-06\n",
      " 7.31526364e-06 5.18548281e-06 3.57886066e-06 2.01822939e-06\n",
      " 6.42082522e-06 1.86814565e-07 6.03090511e-07 6.46593637e-06\n",
      " 7.86172948e-08 4.64057965e-07 1.04493748e-08 9.66889544e-07\n",
      " 2.67373485e-06 1.81192698e-08 9.00193827e-07 1.16747970e-07\n",
      " 1.34985195e-07 5.37363558e-08 2.71099954e-08 1.34051232e-08\n",
      " 9.41412697e-08 7.64604757e-07 2.11436482e-08 3.62058510e-09]\n",
      "step 800 loss:  [7.51239975e-05 1.27633551e-04 1.00184604e-04 5.39267231e-05\n",
      " 6.34994337e-05 1.83633070e-04 9.11624298e-05 1.34879042e-04\n",
      " 1.29349041e-04 1.04116278e-04 1.12047628e-04 6.15382630e-05\n",
      " 8.21822703e-05 1.03387827e-04 8.79958411e-05 8.90613146e-05\n",
      " 4.94751835e-05 1.03045849e-04 8.08427605e-05 1.21974363e-04\n",
      " 1.98012716e-04 6.16961706e-05 5.32702732e-05 1.02162538e-04\n",
      " 1.93431288e-05 1.21756115e-04 6.61021374e-05 7.01033314e-05\n",
      " 2.64701848e-05 2.60747057e-05 5.24582700e-05 4.47046761e-05\n",
      " 7.52834062e-05 1.06715804e-04 5.47053417e-05 4.07733794e-05\n",
      " 1.99412855e-05 1.90422957e-05 4.55366900e-05 4.14543350e-05\n",
      " 5.51057317e-05 6.09214330e-05 6.47121501e-05 5.75631269e-06\n",
      " 3.47272038e-05 3.15839225e-05 4.37660582e-05 1.28360659e-05\n",
      " 4.56098590e-05 2.17260454e-05 2.94031565e-05 1.27302991e-05\n",
      " 2.11188362e-05 2.80457265e-05 1.36124175e-05 8.95087470e-06\n",
      " 1.09183697e-05 8.38281399e-06 1.49199720e-05 1.16505466e-05\n",
      " 1.31677902e-05 9.92675819e-06 1.23395123e-05 1.88505579e-05\n",
      " 4.96988439e-06 7.33737993e-06 1.44985387e-05 2.70824513e-06\n",
      " 8.12505175e-06 3.40880135e-06 1.29961932e-06 2.53666121e-06\n",
      " 4.01588445e-07 6.60733731e-06 1.24254343e-06 3.66286304e-06\n",
      " 3.86986451e-06 2.72605390e-06 1.86953604e-06 1.04753306e-06\n",
      " 3.31101053e-06 9.57011795e-08 3.06895297e-07 3.26817029e-06\n",
      " 3.94658253e-08 2.31349995e-07 5.17304266e-09 4.75286442e-07\n",
      " 1.30492041e-06 8.77925802e-09 4.32981054e-07 5.57393944e-08\n",
      " 6.39651448e-08 2.52716792e-08 1.26522645e-08 6.20793047e-09\n",
      " 4.32571183e-08 3.48562215e-07 9.56210013e-09 1.62422595e-09]\n",
      "step 900 loss:  [5.03369558e-05 8.55175697e-05 6.71178761e-05 3.61203914e-05\n",
      " 4.25200678e-05 1.22917906e-04 6.09936729e-05 9.01950044e-05\n",
      " 8.64439933e-05 6.95325757e-05 7.47712957e-05 4.10302820e-05\n",
      " 5.47430401e-05 6.87980564e-05 5.84910438e-05 5.91290993e-05\n",
      " 3.28056757e-05 6.82348064e-05 5.34558151e-05 8.05313931e-05\n",
      " 1.30526004e-04 4.06007397e-05 3.49942676e-05 6.69891353e-05\n",
      " 1.26591518e-05 7.95240186e-05 4.30841133e-05 4.55930764e-05\n",
      " 1.71767210e-05 1.68806908e-05 3.38794800e-05 2.87999781e-05\n",
      " 4.83748194e-05 6.83902490e-05 3.49627018e-05 2.59852093e-05\n",
      " 1.26718895e-05 1.20645380e-05 2.87620916e-05 2.61012330e-05\n",
      " 3.45847272e-05 3.81082186e-05 4.03422175e-05 3.57608765e-06\n",
      " 2.14974958e-05 1.94806230e-05 2.68941216e-05 7.85777259e-06\n",
      " 2.78123872e-05 1.31958287e-05 1.77865132e-05 7.66903593e-06\n",
      " 1.26689865e-05 1.67522341e-05 8.09542893e-06 5.29947763e-06\n",
      " 6.43506262e-06 4.91786516e-06 8.71186253e-06 6.77033140e-06\n",
      " 7.61485353e-06 5.71222789e-06 7.06496319e-06 1.07377760e-05\n",
      " 2.81630078e-06 4.13600223e-06 8.12896745e-06 1.51020152e-06\n",
      " 4.50581368e-06 1.87980728e-06 7.12617872e-07 1.38291762e-06\n",
      " 2.17657035e-07 3.55991810e-06 6.65443973e-07 1.94971597e-06\n",
      " 2.04720596e-06 1.43311050e-06 9.76613881e-07 5.43707029e-07\n",
      " 1.70738034e-06 4.90257050e-08 1.56170130e-07 1.65187785e-06\n",
      " 1.98118159e-08 1.15336497e-07 2.56095421e-09 2.33632894e-07\n",
      " 6.36868413e-07 4.25377911e-09 2.08258030e-07 2.66118553e-08\n",
      " 3.03110260e-08 1.18850219e-08 5.90482566e-09 2.87490090e-09\n",
      " 1.98762805e-08 1.58899898e-07 4.32440788e-09 7.28641880e-10]\n",
      "final loss: [3.38636777e-05 5.75287507e-05 4.51455606e-05 2.42907756e-05\n",
      " 2.85864223e-05 8.26081250e-05 4.09731159e-05 6.05575249e-05\n",
      " 5.80038357e-05 4.66241905e-05 5.00983961e-05 2.74678191e-05\n",
      " 3.66137474e-05 4.59676037e-05 3.90382484e-05 3.94177929e-05\n",
      " 2.18421279e-05 4.53703020e-05 3.54932068e-05 5.33906121e-05\n",
      " 8.63994468e-05 2.68303863e-05 2.30852070e-05 4.41113090e-05\n",
      " 8.32000743e-06 5.21621857e-05 2.82018630e-05 2.97801948e-05\n",
      " 1.11944231e-05 1.09761316e-05 2.19764874e-05 1.86354966e-05\n",
      " 3.12219664e-05 4.40242510e-05 2.24452520e-05 1.66353613e-05\n",
      " 8.08907235e-06 7.67863764e-06 1.82505048e-05 1.65105364e-05\n",
      " 2.18069567e-05 2.39499549e-05 2.52688783e-05 2.23223182e-06\n",
      " 1.33717655e-05 1.20736408e-05 1.66070347e-05 4.83390709e-06\n",
      " 1.70437835e-05 8.05486186e-06 1.08136103e-05 4.64348361e-06\n",
      " 7.63893908e-06 1.00581176e-05 4.83951034e-06 3.15411099e-06\n",
      " 3.81279810e-06 2.90054453e-06 5.11435167e-06 3.95576896e-06\n",
      " 4.42780740e-06 3.30524477e-06 4.06765109e-06 6.15104030e-06\n",
      " 1.60501264e-06 2.34482331e-06 4.58415638e-06 8.47068173e-07\n",
      " 2.51351136e-06 1.04282119e-06 3.93103450e-07 7.58516114e-07\n",
      " 1.18692778e-07 1.92992041e-06 3.58610842e-07 1.04438473e-06\n",
      " 1.08991507e-06 7.58258808e-07 5.13490075e-07 2.84060068e-07\n",
      " 8.86290907e-07 2.52833921e-08 8.00091454e-08 8.40648509e-07\n",
      " 1.00142942e-08 5.79011308e-08 1.27676512e-09 1.15663616e-07\n",
      " 3.13062276e-07 2.07605514e-09 1.00905140e-07 1.27996746e-08\n",
      " 1.44710924e-08 5.63173509e-09 2.77686975e-09 1.34165901e-09\n",
      " 9.20428115e-09 7.30093523e-08 1.97127076e-09 3.29505856e-10]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    loss = mse(y, a * x + b)\n",
    "    a, b = optimize(x, y, a, b)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"step {i} loss: \", loss)\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "xOgRcPC1LAsq",
    "outputId": "85b0b3e4-aa0d-467a-d8ff-5f01be17b243",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2d97a8c5e0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, a * x + b, color=\"g\", linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOr2fWYpLAsq"
   },
   "source": [
    "Udało ci się wytrenować swoją pierwszą sieć neuronową. Czemu? Otóż neuron to po prostu wektor parametrów, a zwykle robimy iloczyn skalarny tych parametrów z wejściem. Dodatkowo na wyjście nakłada się **funkcję aktywacji (activation function)**, która przekształca wyjście. Tutaj takiej nie było, a właściwie była to po prostu funkcja identyczności.\n",
    "\n",
    "Oczywiście w praktyce korzystamy z odpowiedniego frameworka, który w szczególności:\n",
    "- ułatwia budowanie sieci, np. ma gotowe klasy dla warstw neuronów\n",
    "- ma zaimplementowane funkcje kosztu oraz ich pochodne\n",
    "- sam różniczkuje ze względu na odpowiednie parametry i aktualizuje je odpowiednio podczas treningu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJBYJabuLAsr"
   },
   "source": [
    "## Wprowadzenie do PyTorcha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB-99XqhLAsr"
   },
   "source": [
    "PyTorch to w gruncie rzeczy narzędzie do algebry liniowej z [automatycznym rożniczkowaniem](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html), z możliwością przyspieszenia obliczeń z pomocą GPU. Na tych fundamentach zbudowany jest pełny framework do uczenia głębokiego. Można spotkać się ze stwierdzenie, że PyTorch to NumPy + GPU + opcjonalne różniczkowanie, co jest całkiem celne. Plus można łatwo debugować printem :)\n",
    "\n",
    "PyTorch używa dynamicznego grafu obliczeń, który sami definiujemy w kodzie. Takie podejście jest bardzo wygodne, elastyczne i pozwala na łatwe eksperymentowanie. Odbywa się to potencjalnie kosztem wydajności, ponieważ pozostawia kwestię optymalizacji programiście. Więcej na ten temat dla zainteresowanych na końcu laboratorium.\n",
    "\n",
    "Samo API PyTorcha bardzo przypomina Numpy'a, a podstawowym obiektem jest `Tensor`, klasa reprezentująca tensory dowolnego wymiaru. Dodatkowo niektóre tensory będą miały automatycznie obliczony gradient. Co ważne, tensor jest na pewnym urządzeniu, CPU lub GPU, a przenosić między nimi trzeba explicite.\n",
    "\n",
    "Najważniejsze moduły:\n",
    "- `torch` - podstawowe klasy oraz funkcje, np. `Tensor`, `from_numpy()`\n",
    "- `torch.nn` - klasy związane z sieciami neuronowymi, np. `Linear`, `Sigmoid`\n",
    "- `torch.optim` - wszystko związane z optymalizacją, głównie spadkiem wzdłuż gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FwuIt8S-LAss"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce GTX 1050')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfCiUFXULAss",
    "outputId": "83f6231d-ecc4-461a-b758-fdc4bc2a88a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4424, 1.3548, 1.0655, 1.0342, 1.1398, 1.8602, 1.2447, 1.1196, 1.2807,\n",
      "        1.2700])\n",
      "tensor([0.4424, 0.3548, 0.0655, 0.0342, 0.1398, 0.8602, 0.2447, 0.1196, 0.2807,\n",
      "        0.2700])\n",
      "tensor(2.8120)\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(10)\n",
    "noise = torch.ones(10) * torch.rand(10)\n",
    "\n",
    "# elementwise sum\n",
    "print(ones + noise)\n",
    "\n",
    "# elementwise multiplication\n",
    "print(ones * noise)\n",
    "\n",
    "# dot product\n",
    "print(ones @ noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ynNd_kD0LAst"
   },
   "outputs": [],
   "source": [
    "# beware - shares memory with original Numpy array!\n",
    "# very fast, but modifications are visible to original variable\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9kkxczELAsu"
   },
   "source": [
    "Jeżeli dla stworzonych przez nas tensorów chcemy śledzić operacje i obliczać gradient, to musimy oznaczyć `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HtZL-KfLAsu",
    "outputId": "47c6d930-5678-452a-95bc-227935138b40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9301], requires_grad=True), tensor([0.6669], requires_grad=True))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl1guWZ_LAsv"
   },
   "source": [
    "PyTorch zawiera większość powszechnie używanych funkcji kosztu, np. MSE. Mogą być one używane na 2 sposoby, z czego pierwszy jest popularniejszy:\n",
    "- jako klasy wywoływalne z modułu `torch.nn`\n",
    "- jako funkcje z modułu `torch.nn.functional`\n",
    "\n",
    "Po wykonaniu poniższego kodu widzimy, że zwraca on nam tensor z dodatkowymi atrybutami. Co ważne, jest to skalar (0-wymiarowy tensor), bo potrzebujemy zwyczajnej liczby do obliczania propagacji wstecznych (pochodnych czątkowych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4020, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "mse(y, a * x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS35r49nLAsw"
   },
   "source": [
    "Atrybutu `grad_fn` nie używamy wprost, bo korzysta z niego w środku PyTorch, ale widać, że tensor jest \"świadomy\", że liczy się na nim pochodną. Możemy natomiast skorzystać z atrybutu `grad`, który zawiera faktyczny gradient. Zanim go jednak dostaniemy, to trzeba powiedzieć PyTorchowi, żeby policzył gradient. Służy do tego metoda `.backward()`, wywoływana na obiekcie zwracanym przez funkcję kosztu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Qb7l6Xg1LAsx"
   },
   "outputs": [],
   "source": [
    "loss = mse(y, a * x + b)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LfQbLVoLAsx",
    "outputId": "d5b87fb7-d284-423c-f467-b677384b2f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6191])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kdf1iweELAsy"
   },
   "source": [
    "Ważne jest, że PyTorch nie liczy za każdym razem nowego gradientu, tylko dodaje go do istniejącego, czyli go akumuluje. Jest to przydatne w niektórych sieciach neuronowych, ale zazwyczaj trzeba go zerować. Jeżeli tego nie zrobimy, to dostaniemy coraz większe gradienty.\n",
    "\n",
    "Do zerowania służy metoda `.zero_()`. W PyTorchu wszystkie metody modyfikujące tensor w miejscu mają `_` na końcu nazwy. Jest to dość niskopoziomowa operacja dla pojedynczych tensorów - zobaczymy za chwilę, jak to robić łatwiej dla całej sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiCQZKJsLAsy",
    "outputId": "2f779622-480d-43fc-b9d0-a0e36ff4b28b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2381])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(y, a * x + b)\n",
    "loss.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNC3Ag8uLAsz"
   },
   "source": [
    "Zobaczmy, jak wyglądałaby regresja liniowa, ale napisana w PyTorchu. Jest to oczywiście bardzo niskopoziomowa implementacja - za chwilę zobaczymy, jak to wygląda w praktyce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKnxyeboLAsz",
    "outputId": "2f939474-901a-4773-9704-686a40ae6e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss:  tensor(0.4020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 100 loss:  tensor(0.0106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 200 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 300 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 400 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 500 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 600 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 700 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 800 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "step 900 loss:  tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "final loss: tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "for i in range(1000):\n",
    "    loss = mse(y, a * x + b)\n",
    "\n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    a.data -= learning_rate * a.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "\n",
    "    # zero gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"step {i} loss: \", loss)\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DXNVhshmmI-"
   },
   "source": [
    "Trening modeli w PyTorchu jest dosyć schematyczny i najczęściej rozdziela się go na kilka bloków, dających razem **pętlę uczącą (training loop)**, powtarzaną w każdej epoce:\n",
    "1. Forward pass - obliczenie predykcji sieci\n",
    "2. Loss calculation\n",
    "3. Backpropagation - obliczenie pochodnych oraz zerowanie gradientów\n",
    "4. Optimalization - aktualizacja wag\n",
    "5. Other - ewaluacja na zbiorze walidacyjnym, logging etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2etpw7TNLAs0",
    "outputId": "8ac35c12-6c70-41ec-bf57-414456fc3c96",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss: 0.5579\n",
      "step 100 loss: 0.0117\n",
      "step 200 loss: 0.0102\n",
      "step 300 loss: 0.0101\n",
      "step 400 loss: 0.0101\n",
      "step 500 loss: 0.0101\n",
      "step 600 loss: 0.0101\n",
      "step 700 loss: 0.0101\n",
      "step 800 loss: 0.0101\n",
      "step 900 loss: 0.0101\n",
      "final loss: tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "learning_rate = 0.1\n",
    "a = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([a, b], lr=learning_rate)\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "# training loop in each epoch\n",
    "for i in range(1000):\n",
    "    # forward pass\n",
    "    y_hat = a * x + b\n",
    "\n",
    "    # loss calculation\n",
    "    loss = mse(y, y_hat)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # optimization\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()  # zeroes all gradients - very convenient!\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        if loss < best_loss:\n",
    "            best_model = (a.clone(), b.clone())\n",
    "            best_loss = loss\n",
    "        print(f\"step {i} loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"final loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejdziemy teraz do budowy sieci neuronowej do klasyfikacji. Typowo implementuje się ją po prostu jako sieć dla regresji, ale zwracającą tyle wyników, ile mamy klas, a potem aplikuje się na tym funkcję sigmoidalną (2 klasy) lub softmax (>2 klasy). W przypadku klasyfikacji binarnej zwraca się czasem tylko 1 wartość, przepuszczaną przez sigmoidę - wtedy wyjście z sieci to prawdopodobieństwo klasy pozytywnej.\n",
    "\n",
    "Funkcją kosztu zwykle jest **entropia krzyżowa (cross-entropy)**, stosowana też w klasycznej regresji logistycznej. Co ważne, sieci neuronowe, nawet tak proste, uczą się szybciej i stabilniej, gdy dane na wejściu (a przynajmniej zmienne numeryczne) są **ustandaryzowane (standardized)**. Operacja ta polega na odjęciu średniej i podzieleniu przez odchylenie standardowe (tzw. *Z-score transformation*).\n",
    "\n",
    "**Uwaga - PyTorch wymaga tensora klas będącego liczbami zmiennoprzecinkowymi!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na tym laboratorium wykorzystamy zbiór [Adult Census](https://archive.ics.uci.edu/ml/datasets/adult). Dotyczy on przewidywania na podstawie danych demograficznych, czy dany człowiek zarabia powyżej 50 tysięcy dolarów miesięcznie, czy też mniej. Jest to cenna informacja np. przy planowaniu kampanii marketingowych. Jak możesz się domyślić, zbiór pochodzi z czasów, kiedy inflacja była dużo niższa :)\n",
    "\n",
    "Poniżej znajduje się kod do ściągnięcia i preprocessingu zbioru. Nie musisz go dokładnie analizować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DNsaZAnLAs0",
    "outputId": "70822008-530d-4173-deb9-8149a9fe5b41",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-07 08:39:03--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3974305 (3.8M) [application/x-httpd-php]\n",
      "Saving to: ‘adult.data.3’\n",
      "\n",
      "adult.data.3        100%[===================>]   3.79M   788KB/s    in 5.1s    \n",
      "\n",
      "2022-12-07 08:39:10 (756 KB/s) - ‘adult.data.3’ saved [3974305/3974305]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"wage\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "age: continuous.\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous.\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "education-num: continuous.\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "sex: Female, Male.\n",
    "capital-gain: continuous.\n",
    "capital-loss: continuous.\n",
    "hours-per-week: continuous.\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"adult.data\", header=None, names=columns)\n",
    "df.wage.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribution: https://www.kaggle.com/code/royshih23/topic7-classification-in-python\n",
    "df[\"education\"].replace(\"Preschool\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"10th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"11th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"12th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"1st-4th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"5th-6th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"7th-8th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"9th\", \"dropout\", inplace=True)\n",
    "df[\"education\"].replace(\"HS-Grad\", \"HighGrad\", inplace=True)\n",
    "df[\"education\"].replace(\"HS-grad\", \"HighGrad\", inplace=True)\n",
    "df[\"education\"].replace(\"Some-college\", \"CommunityCollege\", inplace=True)\n",
    "df[\"education\"].replace(\"Assoc-acdm\", \"CommunityCollege\", inplace=True)\n",
    "df[\"education\"].replace(\"Assoc-voc\", \"CommunityCollege\", inplace=True)\n",
    "df[\"education\"].replace(\"Bachelors\", \"Bachelors\", inplace=True)\n",
    "df[\"education\"].replace(\"Masters\", \"Masters\", inplace=True)\n",
    "df[\"education\"].replace(\"Prof-school\", \"Masters\", inplace=True)\n",
    "df[\"education\"].replace(\"Doctorate\", \"Doctorate\", inplace=True)\n",
    "\n",
    "df[\"marital-status\"].replace(\"Never-married\", \"NotMarried\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Married-AF-spouse\"], \"Married\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Married-civ-spouse\"], \"Married\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Married-spouse-absent\"], \"NotMarried\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Separated\"], \"Separated\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Divorced\"], \"Separated\", inplace=True)\n",
    "df[\"marital-status\"].replace([\"Widowed\"], \"Widowed\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiOxs_6mLAs1",
    "outputId": "c95418cf-2632-41d0-de0a-9caf109de113",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20838, 108), (20838,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "\n",
    "X = df.copy()\n",
    "y = (X.pop(\"wage\") == \" >50K\").astype(int).values\n",
    "\n",
    "train_valid_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=train_valid_size, random_state=0, shuffle=True, stratify=y\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=train_valid_size,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    "    stratify=y_train,\n",
    ")\n",
    "\n",
    "continuous_cols = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"education-num\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "]\n",
    "continuous_X_train = X_train[continuous_cols]\n",
    "categorical_X_train = X_train.loc[:, ~X_train.columns.isin(continuous_cols)]\n",
    "\n",
    "continuous_X_valid = X_valid[continuous_cols]\n",
    "categorical_X_valid = X_valid.loc[:, ~X_valid.columns.isin(continuous_cols)]\n",
    "\n",
    "continuous_X_test = X_test[continuous_cols]\n",
    "categorical_X_test = X_test.loc[:, ~X_test.columns.isin(continuous_cols)]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "continuous_scaler = StandardScaler()  # MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "categorical_encoder.fit(categorical_X_train)\n",
    "continuous_scaler.fit(continuous_X_train)\n",
    "\n",
    "continuous_X_train = continuous_scaler.transform(continuous_X_train)\n",
    "continuous_X_valid = continuous_scaler.transform(continuous_X_valid)\n",
    "continuous_X_test = continuous_scaler.transform(continuous_X_test)\n",
    "\n",
    "categorical_X_train = categorical_encoder.transform(categorical_X_train)\n",
    "categorical_X_valid = categorical_encoder.transform(categorical_X_valid)\n",
    "categorical_X_test = categorical_encoder.transform(categorical_X_test)\n",
    "\n",
    "X_train = np.concatenate([continuous_X_train, categorical_X_train], axis=1)\n",
    "X_valid = np.concatenate([continuous_X_valid, categorical_X_valid], axis=1)\n",
    "X_test = np.concatenate([continuous_X_test, categorical_X_test], axis=1)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga co do typów - PyTorchu wszystko w sieci neuronowej musi być typu `float32`. W szczególności trzeba uważać na konwersje z Numpy'a, który używa domyślnie typu `float64`. Może ci się przydać metoda `.float()`.\n",
    "\n",
    "Uwaga co do kształtów wyjścia - wejścia do `nn.BCELoss` muszą być tego samego kształtu. Może ci się przydać metoda `.squeeze()` lub `.unsqueeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qfRA3xEoLAs1"
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float().unsqueeze(-1)\n",
    "\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "y_valid = torch.from_numpy(y_valid).float().unsqueeze(-1)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie jak w laboratorium 2, mamy tu do czynienia z klasyfikacją niezbalansowaną:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pos_perc = 100 * y_train.sum().item() / len(y_train)\n",
    "y_neg_perc = 100 - y_pos_perc\n",
    "\n",
    "plt.title(\"Class percentages\")\n",
    "plt.bar([\"<50k\", \">=50k\"], [y_neg_perc, y_pos_perc])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W związku z powyższym będziemy używać odpowiednich metryk, czyli AUROC, precyzji i czułości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLexWff-LAs0"
   },
   "source": [
    "#### Zadanie 3 (1 punkt)\n",
    "\n",
    "Zaimplementuj regresję logistyczną dla tego zbioru danych, używając PyTorcha. Dane wejściowe zostały dla ciebie przygotowane w komórkach poniżej.\n",
    "\n",
    "Sama sieć składa się z 2 elementów:\n",
    "- warstwa liniowa `nn.Linear`, przekształcająca wektor wejściowy na 1 wyjście - logit\n",
    "- aktywacja sigmoidalna `nn.Sigmoid`, przekształcająca logit na prawdopodobieństwo klasy pozytywnej\n",
    "\n",
    "Użyj binarnej entropii krzyżowej `nn.BCELoss` jako funkcji kosztu. Użyj optymalizatora SGD ze stałą uczącą `1e-3`. Trenuj przez 3000 epok. Pamiętaj, aby przekazać do optymalizatora `torch.optim.SGD` parametry sieci (metoda `.parameters()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbABKz5-LAs2",
    "outputId": "086dc0f3-0184-4072-9fd3-275b60dee2e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6807010769844055\n",
      "100 0.649203896522522\n",
      "200 0.6229594945907593\n",
      "300 0.6009277701377869\n",
      "400 0.5822781920433044\n",
      "500 0.5663520097732544\n",
      "600 0.5526294708251953\n",
      "700 0.5406997799873352\n",
      "800 0.5302386283874512\n",
      "900 0.5209885239601135\n",
      "1000 0.5127447843551636\n",
      "1100 0.5053434371948242\n",
      "1200 0.49865272641181946\n",
      "1300 0.49256598949432373\n",
      "1400 0.4869964122772217\n",
      "1500 0.4818730056285858\n",
      "1600 0.47713711857795715\n",
      "1700 0.4727402925491333\n",
      "1800 0.4686420261859894\n",
      "1900 0.46480831503868103\n",
      "2000 0.4612103998661041\n",
      "2100 0.457823783159256\n",
      "2200 0.45462772250175476\n",
      "2300 0.4516041576862335\n",
      "2400 0.4487375319004059\n",
      "2500 0.4460144340991974\n",
      "2600 0.44342297315597534\n",
      "2700 0.44095268845558167\n",
      "2800 0.43859437108039856\n",
      "2900 0.43634000420570374\n",
      "final loss: 0.4342\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "model = nn.Linear(X_train.shape[1], 1)\n",
    "activation = nn.Sigmoid()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for step in range(3000):\n",
    "    y_pred = activation(model(X_train))\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    if step % 100 == 0:\n",
    "        print(step, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(f\"final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz trzeba sprawdzić, jak poszło naszej sieci. W PyTorchu sieć pracuje zawsze w jednym z dwóch trybów: treningowym lub ewaluacyjnym (predykcyjnym). Ten drugi wyłącza niektóre mechanizmy, które są używane tylko podczas treningu, w szczególności regularyzację dropout. Do przełączania służą metody modelu `.train()` i `.eval()`.\n",
    "\n",
    "Dodatkowo podczas liczenia predykcji dobrze jest wyłączyć liczenie gradientów, bo nie będą potrzebne, a oszczędza to czas i pamięć. Używa się do tego menadżera kontekstu `with torch.no_grad():`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zH37zDX4LAs2",
    "outputId": "b1f93309-6f04-4ffc-b0ca-08d0a32120a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 85.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_score = activation(model(X_test))\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_score)\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest to całkiem dobry wynik, a może być jeszcze lepszy. Sprawdźmy dla pewności jeszcze inne metryki: precyzję, recall oraz F1-score. Dodatkowo narysujemy krzywą precision-recall, czyli jak zmieniają się te metryki w zależności od przyjętego progu (threshold) prawdopodobieństwa, powyżej którego przyjmujemy klasę pozytywną. Taką krzywą należy rysować na zbiorze walidacyjnym, bo później chcemy wykorzystać tę informację do doboru progu, a nie chcemy mieć wycieku danych testowych (data leakage).\n",
    "\n",
    "Poniżej zaimplementowano także funkcję `get_optimal_threshold()`, która sprawdza, dla którego progu uzyskujemy maksymalny F1-score, i zwraca indeks oraz wartość optymalnego progu. Przyda ci się ona w dalszej części laboratorium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "def get_optimal_threshold(\n",
    "    precisions: np.array, recalls: np.array, thresholds: np.array\n",
    ") -> Tuple[int, float]:\n",
    "    f1_scores = 2 * precisions * recalls / (precisions + recalls)\n",
    "\n",
    "    optimal_idx = np.nanargmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    return optimal_idx, optimal_threshold\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred_score) -> None:\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred_score)\n",
    "    optimal_idx, optimal_threshold = get_optimal_threshold(\n",
    "        precisions, recalls, thresholds\n",
    "    )\n",
    "\n",
    "    disp = PrecisionRecallDisplay(precisions, recalls)\n",
    "    disp.plot()\n",
    "    plt.title(f\"Precision-recall curve (opt. thresh.: {optimal_threshold:.4f})\")\n",
    "    plt.axvline(recalls[optimal_idx], color=\"green\", linestyle=\"-.\")\n",
    "    plt.axhline(precisions[optimal_idx], color=\"green\", linestyle=\"-.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_valid_score = activation(model(X_valid))\n",
    "\n",
    "plot_precision_recall_curve(y_valid, y_pred_valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfQPIUQ_LAs2"
   },
   "source": [
    "Jak widać, chociaż AUROC jest wysokie, to dla optymalnego F1-score recall nie jest zbyt wysoki, a precyzja jest już dość niska. Być może wynik uda się poprawić, używając modelu o większej pojemności - pełnej, głębokiej sieci neuronowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YP298w6Cq7T6"
   },
   "source": [
    "Wszystko zaczęło się od inspirowanych biologią [sztucznych neuronów](https://en.wikipedia.org/wiki/Artificial_neuron), których próbowano użyć do symulacji mózgu. Naukowcy szybko odeszli od tego podejścia (sam problem modelowania okazał się też znacznie trudniejszy, niż sądzono), zamiast tego używając neuronów jako jednostek reprezentującą dowolną funkcję parametryczną $f(x, \\Theta)$. Każdy neuron jest zatem bardzo elastyczny, bo jedyne wymagania to funkcja różniczkowalna, a mamy do tego wektor parametrów $\\Theta$.\n",
    "\n",
    "W praktyce najczęściej można spotkać się z kilkoma rodzinami sieci neuronowych:\n",
    "1. Perceptrony wielowarstwowe (*MultiLayer Perceptron*, MLP) - najbardziej podobne do powyższego opisu, niezbędne do klasyfikacji i regresji\n",
    "2. Konwolucyjne (*Convolutional Neural Networks*, CNNs) - do przetwarzania danych z zależnościami przestrzennymi, np. obrazów czy dźwięku\n",
    "3. Rekurencyjne (*Recurrent Neural Networks*, RNNs) - do przetwarzania danych z zależnościami sekwencyjnymi, np. szeregi czasowe, oraz kiedyś do języka naturalnego\n",
    "4. Transformacyjne (*Transformers*), oparte o mechanizm atencji (*attention*) - do przetwarzania języka naturalnego (NLP), z którego wyparły RNNs, a coraz częściej także do wszelkich innych danych, np. obrazów, dźwięku\n",
    "5. Grafowe (*Graph Neural Networks*, GNNS) - do przetwarzania grafów\n",
    "\n",
    "Na tym laboratorium skupimy się na najprostszej architekturze, czyli MLP. Jest ona powszechnie łączona z wszelkimi innymi architekturami, bo pozwala dokonywać klasyfikacji i regresji. Przykładowo, klasyfikacja obrazów to zwykle CNN + MLP, klasyfikacja tekstów to transformer + MLP, a regresja na grafach to GNN + MLP.\n",
    "\n",
    "Dodatkowo, pomimo prostoty MLP są bardzo potężne - udowodniono, że perceptrony (ich powszechna nazwa) są [uniwersalnym aproksymatorem](https://www.sciencedirect.com/science/article/abs/pii/0893608089900208), będącym w stanie przybliżyć dowolną funkcję z odpowiednio małym błędem, zakładając wystarczającą wielkość warstw sieci. Szczególne ich wersje potrafią nawet [reprezentować drzewa decyzyjne](https://www.youtube.com/watch?v=_okxGdHM5b8).\n",
    "\n",
    "Dla zainteresowanych polecamy [doskonałą książkę \"Dive into Deep Learning\", z implementacjami w PyTorchu](https://d2l.ai/chapter_multilayer-perceptrons/index.html), [klasyczną książkę \"Deep Learning Book\"](https://www.deeplearningbook.org/contents/mlp.html), oraz [ten filmik](https://www.youtube.com/watch?v=BFHrIxKcLjA), jeśli zastanawiałeś/-aś się, czemu używamy deep learning, a nie naprzykład (wide?) learning. (aka. czemu staramy się budować głębokie sieci, a nie płytkie za to szerokie)"
   ]
  },
  {
   "attachments": {
    "1_x-3NGQv0pRIab8xDT-f_Hg.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "id": "S_ZjoGBU5upj"
   },
   "source": [
    "### Sieci MLP\n",
    "\n",
    "Dla przypomnienia, na wejściu mamy punkty ze zbioru treningowego, czyli $d$-wymiarowe wektory. W klasyfikacji chcemy znaleźć granicę decyzyjną, czyli krzywą, która oddzieli od siebie klasy. W wejściowej przestrzeni może być to trudne, bo chmury punktów z poszczególnych klas mogą być ze sobą dość pomieszane. Pamiętajmy też, że regresja logistyczna jest klasyfikatorem liniowym, czyli w danej przestrzeni potrafi oddzielić punkty tylko linią prostą.\n",
    "\n",
    "Sieć MLP składa się z warstw. Każda z nich dokonuje nieliniowego przekształcenia przestrzeni (można o tym myśleć jak o składaniu przestrzeni jakąś prostą/łamaną), tak, aby w finalnej przestrzeni nasze punkty były możliwie liniowo separowalne. Wtedy ostatnia warstwa z sigmoidą będzie potrafiła je rozdzielić od siebie.\n",
    "\n",
    "![1_x-3NGQv0pRIab8xDT-f_Hg.png](attachment:1_x-3NGQv0pRIab8xDT-f_Hg.png)\n",
    "\n",
    "Poszczególne neurony składają się z iloczynu skalarnego wejść z wagami neuronu, oraz nieliniowej funkcji aktywacji. W PyTorchu są to osobne obiekty - `nn.Linear` oraz np. `nn.Sigmoid`. Funkcja aktywacji przyjmuje wynik iloczynu skalarnego i przekształca go, aby sprawdzić, jak mocno reaguje neuron na dane wejście. Musi być nieliniowa z dwóch powodów. Po pierwsze, tylko nieliniowe przekształcenia są na tyle potężne, żeby umożliwić liniową separację danych w ostatniej warstwie. Po drugie, liniowe przekształcenia zwyczajnie nie działają. Aby zrozumieć czemu, trzeba zobaczyć, co matematycznie oznacza sieć MLP.\n",
    "\n",
    "![perceptron](https://www.saedsayad.com/images/Perceptron_bkp_1.png)\n",
    "\n",
    "Zapisane matematycznie MLP to:\n",
    "$\n",
    "h_1 = f_1(x) \\\\\n",
    "h_2 = f_2(h_1) \\\\\n",
    "h_3 = f_3(h_2) \\\\\n",
    "...\n",
    "h_n = f_n(h_{n-1})\n",
    "$\n",
    "gdzie $x$ to wejście $f_i$ to funkcja aktywacji $i$-tej warstwy, a $h_i$ to wyjście $i$-tej warstwy, nazywane **ukrytą reprezentacją (hidden representation)**, lub *latent representation*. Nazwa bierze się z tego, że w środku sieci wyciągamy cechy i wzorce w danych, które nie są widoczne na pierwszy rzut oka na wejściu.\n",
    "\n",
    "Załóżmy, że nie mamy funkcji aktywacji, czyli mamy aktywację liniową $f(x) = x$. Zobaczmy na początku sieci:\n",
    "$\n",
    "h_1 = f_1(x) = x\n",
    "h_2 = f_2(f_1) = f_2(x) = x\n",
    "...\n",
    "h_n = f_n(f_{n-1}) = f_n(x) = x\n",
    "$\n",
    "Jak widać, taka sieć niczego się nie nauczy. Wynika to z tego, że złożenie funkcji liniowych jest także funkcją liniową - patrz notatki z algebry :)\n",
    "\n",
    "Jeżeli natomiast użyjemy nieliniowej funkcji aktywacji, często oznaczanej jako $\\sigma$, to wszystko będzie działać. Co ważne, ostatnia warstwa, dająca wyjście sieci, ma zwykle inną aktywację od warstw wewnątrz sieci, bo też ma inne zadanie - zwrócić wartość dla klasyfikacji lub regresji. Na wyjściu korzysta się z funkcji liniowej (regresja), sigmoidalnej (klasyfikacja binarna) lub softmax (klasyfikacja wieloklasowa).\n",
    "\n",
    "Wewnątrz sieci używano kiedyś sigmoidy oraz tangensa hiperbolicznego `tanh`, ale okazało się to nieefektywne przy uczeniu głębokich sieci o wielu warstwach. Nowoczesne sieci korzystają zwykle z funkcji ReLU (*rectified linear unit*), która jest zaskakująco prosta: $ReLU(x) = \\max(0, x)$. Okazało się, że bardzo dobrze nadaje się do treningu nawet bardzo głębokich sieci neuronowych. Nowsze funkcje aktywacji są głównie modyfikacjami ReLU.\n",
    "\n",
    "![relu](https://www.nomidl.com/wp-content/uploads/2022/04/image-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP w PyTorchu\n",
    "\n",
    "Warstwę neuronów w MLP nazywa się warstwą gęstą (*dense layer*) lub warstwą w pełni połączoną (*fully-connected layer*), i taki opis oznacza zwykle same neurony oraz funkcję aktywacji. PyTorch, jak już widzieliśmy, definiuje osobno transformację liniową oraz aktywację, a więc jedna warstwa składa się de facto z 2 obiektów, wywoływanych jeden po drugim. Inne frameworki, szczególnie wysokopoziomowe (np. Keras) łączą to często w jeden obiekt.\n",
    "\n",
    "MLP składa się zatem z sekwencji obiektów, które potem wywołuje się jeden po drugim, gdzie wyjście poprzedniego to wejście kolejnego. Ale nie można tutaj używać Pythonowych list! Z perspektywy PyTorcha to wtedy niezależne obiekty i nie zostanie wtedy przekazany między nimi gradient. Trzeba tutaj skorzystać z `nn.Sequential`, aby tworzyć taki pipeline.\n",
    "\n",
    "Rozmiary wejścia i wyjścia dla każdej warstwy trzeba w PyTorchu podawać explicite. Jest to po pierwsze edukacyjne, a po drugie często ułatwia wnioskowanie o działaniu sieci oraz jej debugowanie - mamy jasno podane, czego oczekujemy. Niektóre frameworki (np. Keras) obliczają to automatycznie.\n",
    "\n",
    "Co ważne, ostatnia warstwa zwykle nie ma funkcji aktywacji. Wynika to z tego, że obliczanie wielu funkcji kosztu (np. entropii krzyżowej) na aktywacjach jest często niestabilne numerycznie. Z tego powodu PyTorch oferuje funkcje kosztu zawierające w środku aktywację dla ostatniej warstwy, a ich implementacje są stabilne numerycznie. Przykładowo, `nn.BCELoss` przyjmuje wejście z zaaplikowanymi już aktywacjami, ale może skutkować under/overflow, natomiast `nn.BCEWithLogitsLoss` przyjmuje wejście bez aktywacji, a w środku ma specjalną implementację łączącą binarną entropię krzyżową z aktywacją sigmoidalną. Oczywiście w związku z tym aby dokonać potem predykcji w praktyce, trzeba pamiętać o użyciu funkcji aktywacji. Często korzysta się przy tym z funkcji z modułu `torch.nn.functional`, które są w tym wypadku nieco wygodniejsze od klas wywoływalnych z `torch.nn`.\n",
    "\n",
    "Całe sieci w PyTorchu tworzy się jako klasy dziedziczące po `nn.Module`. Co ważne, obiekty, z których tworzymy sieć, np. `nn.Linear`, także dziedziczą po tej klasie. Pozwala to na bardzo modułową budowę kodu, zgodną z zasadami OOP. W konstruktorze najpierw trzeba zawsze wywołać konstruktor rodzica - `super().__init__()`, a później tworzy się potrzebne obiekty i zapisuje jako atrybuty. Musimy też zdefiniować metodę `forward()`, która przyjmuje tensor `x` i zwraca wynik. Typowo ta metoda po prostu używa obiektów zdefiniowanych w konstruktorze.\n",
    "\n",
    "\n",
    "**UWAGA: nigdy w normalnych warunkach się nie woła metody `forward` ręcznie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8niDgExAMDO"
   },
   "source": [
    "#### Zadanie 4 (1 punkt)\n",
    "\n",
    "Uzupełnij implementację 3-warstwowej sieci MLP. Użyj rozmiarów:\n",
    "* pierwsza warstwa: input_size x 256\n",
    "* druga warstwa: 256 x 128\n",
    "* trzecia warstwa: 128 x 1\n",
    "\n",
    "Użyj funkcji aktywacji ReLU.\n",
    "\n",
    "Przydatne klasy:\n",
    "- `nn.Sequential`\n",
    "- `nn.Linear`\n",
    "- `nn.ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZpuVDz1ALU5",
    "outputId": "cfe0d6ac-d2ce-43dd-cc22-837063f0f6bf"
   },
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return torch.argmax(y_pred_score, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.6884\n",
      "Epoch 200 train loss: 0.6633\n",
      "Epoch 400 train loss: 0.6422\n",
      "Epoch 600 train loss: 0.6240\n",
      "Epoch 800 train loss: 0.6082\n",
      "Epoch 1000 train loss: 0.5943\n",
      "Epoch 1200 train loss: 0.5820\n",
      "Epoch 1400 train loss: 0.5712\n",
      "Epoch 1600 train loss: 0.5616\n",
      "Epoch 1800 train loss: 0.5531\n",
      "final loss: 0.5456\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "model = MLP(input_size=X_train.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# note that we are using loss function with sigmoid built in\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "num_epochs = 2000\n",
    "evaluation_steps = 200\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % evaluation_steps == 0:\n",
    "        print(f\"Epoch {i} train loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP5GSup24dXU",
    "outputId": "05f332c4-5d94-41f6-f85b-17793d3c4b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC: 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # positive class probabilities\n",
    "    y_pred_valid_score = model.predict_proba(X_valid)\n",
    "    y_pred_test_score = model.predict_proba(X_test)\n",
    "\n",
    "auroc = roc_auc_score(y_test, y_pred_test_score)\n",
    "print(f\"AUROC: {100 * auroc:.2f}%\")\n",
    "\n",
    "plot_precision_recall_curve(y_valid, y_pred_valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC jest podobne, a precision i recall spadły - wypadamy wręcz gorzej od regresji liniowej! Skoro dodaliśmy więcej warstw, to może pojemność modelu jest teraz za duża i trzeba by go zregularyzować?\n",
    "\n",
    "Sieci neuronowe bardzo łatwo przeuczają, bo są bardzo elastycznymi i pojemnymi modelami. Dlatego mają wiele różnych rodzajów regularyzacji, których używa się razem. Co ciekawe, udowodniono eksperymentalnie, że zbyt duże sieci z mocną regularyzacją działają lepiej niż mniejsze sieci, odpowiedniego rozmiaru, za to ze słabszą regularyzacją.\n",
    "\n",
    "Pierwszy rodzaj regularyzacji to znana nam już **regularyzacja L2**, czyli penalizacja zbyt dużych wag. W kontekście sieci neuronowych nazywa się też ją czasem *weight decay*. W PyTorchu dodaje się ją jako argument do optymalizatora.\n",
    "\n",
    "Regularyzacja specyficzna dla sieci neuronowych to **dropout**. Polega on na losowym wyłączaniu zadanego procenta neuronów podczas treningu. Pomimo prostoty okazała się niesamowicie skuteczna, szczególnie w treningu bardzo głębokich sieci. Co ważne, jest to mechanizm używany tylko podczas treningu - w trakcie predykcji za pomocą sieci wyłącza się ten mechanizm i dokonuje normalnie predykcji całą siecią. Podejście to można potraktować jak ensemble learning, podobny do lasów losowych - wyłączając losowe części sieci, w każdej iteracji trenujemy nieco inną sieć, co odpowiada uśrednianiu predykcji różnych algorytmów. Typowo stosuje się dość mocny dropout, rzędu 25-50%. W PyTorchu implementuje go warstwa `nn.Dropout`, aplikowana zazwyczaj po funkcji aktywacji.\n",
    "\n",
    "Ostatni, a być może najważniejszy rodzaj regularyzacji to **wczesny stop (early stopping)**. W każdym kroku mocniej dostosowujemy terenową sieć do zbioru treningowego, a więc zbyt długi trening będzie skutkował przeuczeniem. W metodzie wczesnego stopu używamy wydzielonego zbioru walidacyjnego (pojedynczego, metoda holdout), sprawdzając co określoną liczbę epok wynik na tym zbiorze. Jeżeli nie uzyskamy wyniku lepszego od najlepszego dotychczas uzyskanego przez określoną liczbę epok, to przerywamy trening. Okres, przez który czekamy na uzyskanie lepszego wyniku, to cierpliwość (*patience*). Im mniejsze, tym mocniejszy jest ten rodzaj regularyzacji, ale trzeba z tym uważać, bo łatwo jest przesadzić i zbyt szybko przerywać trening. Niektóre implementacje uwzględniają tzw. *grace period*, czyli gwarantowaną minimalną liczbę epok, przez którą będziemy trenować sieć, niezależnie od wybranej cierpliwości.\n",
    "\n",
    "Dodatkowo ryzyko przeuczenia można zmniejszyć, używając mniejszej stałej uczącej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 5 (1 punkt)\n",
    "\n",
    "Zaimplementuj funkcję `evaluate_model()`, obliczającą metryki na zbiorze testowym:\n",
    "- wartość funkcji kosztu (loss)\n",
    "- AUROC\n",
    "- optymalny próg\n",
    "- F1-score przy optymalnym progu\n",
    "- precyzję oraz recall dla optymalnego progu\n",
    "\n",
    "Jeżeli podana jest wartość argumentu `threshold`, to użyj jej do zamiany prawdopodobieństw na twarde predykcje. W przeciwnym razie użyj funkcji `get_optimal_threshold` i oblicz optymalną wartość progu.\n",
    "\n",
    "Pamiętaj o przełączeniu modelu w tryb ewaluacji oraz o wyłączeniu obliczania gradientów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch import sigmoid\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    X: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    loss_fn: nn.Module,\n",
    "    threshold: Optional[float] = None,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_score = model.predict_proba(X)\n",
    "\n",
    "    auroc = roc_auc_score(y, y_pred_score)\n",
    "    loss = loss_fn(y_pred_score, y)\n",
    "    print(y_pred_score)\n",
    "\n",
    "    if threshold is None:\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y, y_pred_score)\n",
    "        _, threshold = get_optimal_threshold(precisions, recalls, thresholds)\n",
    "\n",
    "    y_pred = (y_pred_score > threshold).float()\n",
    "\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "\n",
    "    results = {\n",
    "        \"loss\": loss,\n",
    "        \"AUROC\": auroc,\n",
    "        \"optimal_threshold\": threshold,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 6 (1 punkt)\n",
    "\n",
    "Zaimplementuj 3-warstwową sieć MLP z regularyzacją L2 oraz dropout (50%). Rozmiary warstw ukrytych mają wynosić 256 i 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return torch.argmax(y_pred_score, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEk9azaULAsz"
   },
   "source": [
    "Opisaliśmy wcześniej podstawowy optymalizator w sieciach neuronowych - spadek wzdłuż gradientu. Jednak wymaga on użycia całego zbioru danych, aby obliczyć gradient, co jest często niewykonalne przez rozmiar zbioru. Dlatego wymyślono **stochastyczny spadek wzdłuż gradientu (stochastic gradient descent, SGD)**, w którym używamy 1 przykładu naraz, liczymy gradient tylko po nim i aktualizujemy parametry. Jest to oczywiście dość grube przybliżenie gradientu, ale pozwala robić szybko dużo małych kroków. Kompromisem, którego używa się w praktyce, jest **minibatch gradient descent**, czyli używanie batchy np. 32, 64 czy 128 przykładów.\n",
    "\n",
    "Rzadko wspominanym, a ważnym faktem jest także to, że stochastyczność metody optymalizacji jest sama w sobie też [metodą regularyzacji](https://arxiv.org/abs/2101.12176), a więc `batch_size` to także hiperparametr.\n",
    "\n",
    "Obecnie najpopularniejszą odmianą SGD jest [Adam](https://arxiv.org/abs/1412.6980), gdyż uczy on szybko sieć oraz daje bardzo dobre wyniki nawet przy niekoniecznie idealnie dobranych hiperparametrach. W PyTorchu najlepiej korzystać z jego implementacji `AdamW`, która jest nieco lepsza niż implementacja `Adam`. Jest to zasadniczo zawsze wybór domyślny przy treningu współczesnych sieci neuronowych.\n",
    "\n",
    "Na razie użyjemy jednak minibatch SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się implementacja prostej klasy dziedziczącej po `Dataset` - tak w PyTorchu implementuje się własne zbiory danych. Użycie takich klas umożliwia użycie klas ładujących dane (`DataLoader`), które z kolei pozwalają łatwo ładować batche danych. Trzeba w takiej klasie zaimplementować metody:\n",
    "- `__len__` - zwraca ilość punktów w zbiorze\n",
    "- `__getitem__` - zwraca przykład ze zbioru pod danym indeksem oraz jego klasę\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, y):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = data\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 7 (2 punkty)\n",
    "\n",
    "Zaimplementuj pętlę treningowo-walidacyjną dla sieci neuronowej. Wykorzystaj podane wartości hiperparametrów do treningu (stała ucząca, prawdopodobieństwo dropoutu, regularyzacja L2, rozmiar batcha, maksymalna liczba epok). Użyj optymalizatora SGD.\n",
    "\n",
    "Dodatkowo zaimplementuj regularyzację przez early stopping. Sprawdzaj co epokę wynik na zbiorze walidacyjnym. Użyj podanej wartości patience, a jako metryki po prostu wartości funkcji kosztu. Może się tutaj przydać zaimplementowana funkcja `evaluate_model()`.\n",
    "\n",
    "Pamiętaj o tym, aby przechowywać najlepszy dotychczasowy wynik walidacyjny oraz najlepszy dotychczasowy model. Zapamiętaj też optymalny próg do klasyfikacji dla najlepszego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "dropout_p = 0.5\n",
    "l2_reg = 1e-4\n",
    "batch_size = 128\n",
    "max_epochs = 300\n",
    "\n",
    "early_stopping_patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4788],\n",
      "        [0.4741],\n",
      "        [0.4781],\n",
      "        ...,\n",
      "        [0.4811],\n",
      "        [0.4832],\n",
      "        [0.4799]])\n",
      "Epoch 0 train loss: 0.6741, eval loss 0.8458017110824585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4610],\n",
      "        [0.4588],\n",
      "        [0.4612],\n",
      "        ...,\n",
      "        [0.4619],\n",
      "        [0.4664],\n",
      "        [0.4616]])\n",
      "Epoch 1 train loss: 0.6550, eval loss 0.8391697406768799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4441],\n",
      "        [0.4446],\n",
      "        [0.4455],\n",
      "        ...,\n",
      "        [0.4439],\n",
      "        [0.4503],\n",
      "        [0.4444]])\n",
      "Epoch 2 train loss: 0.6368, eval loss 0.8329811692237854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4279],\n",
      "        [0.4313],\n",
      "        [0.4306],\n",
      "        ...,\n",
      "        [0.4267],\n",
      "        [0.4351],\n",
      "        [0.4278]])\n",
      "Epoch 3 train loss: 0.6226, eval loss 0.8271600604057312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4123],\n",
      "        [0.4189],\n",
      "        [0.4167],\n",
      "        ...,\n",
      "        [0.4105],\n",
      "        [0.4207],\n",
      "        [0.4121]])\n",
      "Epoch 4 train loss: 0.6171, eval loss 0.8216566443443298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3976],\n",
      "        [0.4074],\n",
      "        [0.4037],\n",
      "        ...,\n",
      "        [0.3951],\n",
      "        [0.4069],\n",
      "        [0.3969]])\n",
      "Epoch 5 train loss: 0.5968, eval loss 0.8164405226707458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3835],\n",
      "        [0.3968],\n",
      "        [0.3917],\n",
      "        ...,\n",
      "        [0.3805],\n",
      "        [0.3934],\n",
      "        [0.3825]])\n",
      "Epoch 6 train loss: 0.5847, eval loss 0.8115139603614807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3700],\n",
      "        [0.3870],\n",
      "        [0.3802],\n",
      "        ...,\n",
      "        [0.3665],\n",
      "        [0.3802],\n",
      "        [0.3686]])\n",
      "Epoch 7 train loss: 0.5796, eval loss 0.8068182468414307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3571],\n",
      "        [0.3781],\n",
      "        [0.3693],\n",
      "        ...,\n",
      "        [0.3532],\n",
      "        [0.3674],\n",
      "        [0.3555]])\n",
      "Epoch 8 train loss: 0.5724, eval loss 0.802367627620697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3449],\n",
      "        [0.3701],\n",
      "        [0.3592],\n",
      "        ...,\n",
      "        [0.3406],\n",
      "        [0.3550],\n",
      "        [0.3430]])\n",
      "Epoch 9 train loss: 0.5763, eval loss 0.7981685996055603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3334],\n",
      "        [0.3630],\n",
      "        [0.3500],\n",
      "        ...,\n",
      "        [0.3288],\n",
      "        [0.3431],\n",
      "        [0.3313]])\n",
      "Epoch 10 train loss: 0.5582, eval loss 0.7942276000976562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3226],\n",
      "        [0.3567],\n",
      "        [0.3417],\n",
      "        ...,\n",
      "        [0.3176],\n",
      "        [0.3315],\n",
      "        [0.3203]])\n",
      "Epoch 11 train loss: 0.5632, eval loss 0.7905074954032898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3124],\n",
      "        [0.3510],\n",
      "        [0.3339],\n",
      "        ...,\n",
      "        [0.3070],\n",
      "        [0.3203],\n",
      "        [0.3098]])\n",
      "Epoch 12 train loss: 0.5390, eval loss 0.7869744300842285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3030],\n",
      "        [0.3462],\n",
      "        [0.3272],\n",
      "        ...,\n",
      "        [0.2972],\n",
      "        [0.3098],\n",
      "        [0.3001]])\n",
      "Epoch 13 train loss: 0.5494, eval loss 0.7837116122245789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9711/1491067547.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1_scores = 2 * precisions * recalls / (precisions + recalls)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2941],\n",
      "        [0.3421],\n",
      "        [0.3208],\n",
      "        ...,\n",
      "        [0.2879],\n",
      "        [0.2996],\n",
      "        [0.2909]])\n",
      "Epoch 14 train loss: 0.5346, eval loss 0.7806242108345032\n",
      "tensor([[0.2858],\n",
      "        [0.3386],\n",
      "        [0.3151],\n",
      "        ...,\n",
      "        [0.2791],\n",
      "        [0.2899],\n",
      "        [0.2823]])\n",
      "Epoch 15 train loss: 0.5327, eval loss 0.7777135968208313\n",
      "tensor([[0.2780],\n",
      "        [0.3357],\n",
      "        [0.3101],\n",
      "        ...,\n",
      "        [0.2709],\n",
      "        [0.2806],\n",
      "        [0.2743]])\n",
      "Epoch 16 train loss: 0.5247, eval loss 0.7749885320663452\n",
      "tensor([[0.2709],\n",
      "        [0.3335],\n",
      "        [0.3059],\n",
      "        ...,\n",
      "        [0.2634],\n",
      "        [0.2719],\n",
      "        [0.2669]])\n",
      "Epoch 17 train loss: 0.5297, eval loss 0.7724552154541016\n",
      "tensor([[0.2641],\n",
      "        [0.3319],\n",
      "        [0.3020],\n",
      "        ...,\n",
      "        [0.2562],\n",
      "        [0.2635],\n",
      "        [0.2599]])\n",
      "Epoch 18 train loss: 0.5290, eval loss 0.7700395584106445\n",
      "tensor([[0.2578],\n",
      "        [0.3309],\n",
      "        [0.2989],\n",
      "        ...,\n",
      "        [0.2496],\n",
      "        [0.2555],\n",
      "        [0.2534]])\n",
      "Epoch 19 train loss: 0.5376, eval loss 0.7677903771400452\n",
      "tensor([[0.2521],\n",
      "        [0.3304],\n",
      "        [0.2963],\n",
      "        ...,\n",
      "        [0.2434],\n",
      "        [0.2479],\n",
      "        [0.2474]])\n",
      "Epoch 20 train loss: 0.5174, eval loss 0.7656843662261963\n",
      "tensor([[0.2467],\n",
      "        [0.3305],\n",
      "        [0.2942],\n",
      "        ...,\n",
      "        [0.2375],\n",
      "        [0.2407],\n",
      "        [0.2418]])\n",
      "Epoch 21 train loss: 0.5225, eval loss 0.7637057304382324\n",
      "tensor([[0.2416],\n",
      "        [0.3310],\n",
      "        [0.2925],\n",
      "        ...,\n",
      "        [0.2320],\n",
      "        [0.2337],\n",
      "        [0.2365]])\n",
      "Epoch 22 train loss: 0.5046, eval loss 0.7618287801742554\n",
      "tensor([[0.2369],\n",
      "        [0.3320],\n",
      "        [0.2913],\n",
      "        ...,\n",
      "        [0.2269],\n",
      "        [0.2270],\n",
      "        [0.2316]])\n",
      "Epoch 23 train loss: 0.5074, eval loss 0.7600522637367249\n",
      "tensor([[0.2324],\n",
      "        [0.3332],\n",
      "        [0.2904],\n",
      "        ...,\n",
      "        [0.2219],\n",
      "        [0.2204],\n",
      "        [0.2269]])\n",
      "Epoch 24 train loss: 0.5103, eval loss 0.7583341598510742\n",
      "tensor([[0.2281],\n",
      "        [0.3347],\n",
      "        [0.2896],\n",
      "        ...,\n",
      "        [0.2170],\n",
      "        [0.2141],\n",
      "        [0.2223]])\n",
      "Epoch 25 train loss: 0.5070, eval loss 0.7566712498664856\n",
      "tensor([[0.2243],\n",
      "        [0.3368],\n",
      "        [0.2894],\n",
      "        ...,\n",
      "        [0.2127],\n",
      "        [0.2081],\n",
      "        [0.2183]])\n",
      "Epoch 26 train loss: 0.5045, eval loss 0.7551531791687012\n",
      "tensor([[0.2204],\n",
      "        [0.3391],\n",
      "        [0.2893],\n",
      "        ...,\n",
      "        [0.2083],\n",
      "        [0.2021],\n",
      "        [0.2142]])\n",
      "Epoch 27 train loss: 0.5126, eval loss 0.7536303997039795\n",
      "tensor([[0.2171],\n",
      "        [0.3418],\n",
      "        [0.2898],\n",
      "        ...,\n",
      "        [0.2042],\n",
      "        [0.1965],\n",
      "        [0.2105]])\n",
      "Epoch 28 train loss: 0.5014, eval loss 0.7522291541099548\n",
      "tensor([[0.2138],\n",
      "        [0.3446],\n",
      "        [0.2905],\n",
      "        ...,\n",
      "        [0.2002],\n",
      "        [0.1910],\n",
      "        [0.2069]])\n",
      "Epoch 29 train loss: 0.4953, eval loss 0.7508537173271179\n",
      "tensor([[0.2106],\n",
      "        [0.3476],\n",
      "        [0.2913],\n",
      "        ...,\n",
      "        [0.1963],\n",
      "        [0.1855],\n",
      "        [0.2034]])\n",
      "Epoch 30 train loss: 0.4839, eval loss 0.7494984865188599\n",
      "tensor([[0.2076],\n",
      "        [0.3507],\n",
      "        [0.2924],\n",
      "        ...,\n",
      "        [0.1926],\n",
      "        [0.1801],\n",
      "        [0.2000]])\n",
      "Epoch 31 train loss: 0.4866, eval loss 0.74818354845047\n",
      "tensor([[0.2047],\n",
      "        [0.3542],\n",
      "        [0.2938],\n",
      "        ...,\n",
      "        [0.1890],\n",
      "        [0.1749],\n",
      "        [0.1968]])\n",
      "Epoch 32 train loss: 0.4740, eval loss 0.7469215989112854\n",
      "tensor([[0.2021],\n",
      "        [0.3577],\n",
      "        [0.2957],\n",
      "        ...,\n",
      "        [0.1857],\n",
      "        [0.1699],\n",
      "        [0.1938]])\n",
      "Epoch 33 train loss: 0.4792, eval loss 0.7457336783409119\n",
      "tensor([[0.1995],\n",
      "        [0.3611],\n",
      "        [0.2974],\n",
      "        ...,\n",
      "        [0.1823],\n",
      "        [0.1649],\n",
      "        [0.1908]])\n",
      "Epoch 34 train loss: 0.4881, eval loss 0.7445386648178101\n",
      "tensor([[0.1970],\n",
      "        [0.3649],\n",
      "        [0.2996],\n",
      "        ...,\n",
      "        [0.1791],\n",
      "        [0.1599],\n",
      "        [0.1880]])\n",
      "Epoch 35 train loss: 0.4738, eval loss 0.7433788180351257\n",
      "tensor([[0.1945],\n",
      "        [0.3685],\n",
      "        [0.3018],\n",
      "        ...,\n",
      "        [0.1759],\n",
      "        [0.1550],\n",
      "        [0.1851]])\n",
      "Epoch 36 train loss: 0.4740, eval loss 0.7422137260437012\n",
      "tensor([[0.1923],\n",
      "        [0.3725],\n",
      "        [0.3045],\n",
      "        ...,\n",
      "        [0.1729],\n",
      "        [0.1503],\n",
      "        [0.1825]])\n",
      "Epoch 37 train loss: 0.4820, eval loss 0.741123616695404\n",
      "tensor([[0.1902],\n",
      "        [0.3765],\n",
      "        [0.3075],\n",
      "        ...,\n",
      "        [0.1699],\n",
      "        [0.1457],\n",
      "        [0.1799]])\n",
      "Epoch 38 train loss: 0.4708, eval loss 0.7400516867637634\n",
      "tensor([[0.1881],\n",
      "        [0.3806],\n",
      "        [0.3105],\n",
      "        ...,\n",
      "        [0.1669],\n",
      "        [0.1411],\n",
      "        [0.1773]])\n",
      "Epoch 39 train loss: 0.4679, eval loss 0.738985538482666\n",
      "tensor([[0.1860],\n",
      "        [0.3848],\n",
      "        [0.3137],\n",
      "        ...,\n",
      "        [0.1640],\n",
      "        [0.1366],\n",
      "        [0.1748]])\n",
      "Epoch 40 train loss: 0.4562, eval loss 0.7379171848297119\n",
      "tensor([[0.1840],\n",
      "        [0.3891],\n",
      "        [0.3171],\n",
      "        ...,\n",
      "        [0.1611],\n",
      "        [0.1322],\n",
      "        [0.1723]])\n",
      "Epoch 41 train loss: 0.4632, eval loss 0.7369095683097839\n",
      "tensor([[0.1822],\n",
      "        [0.3935],\n",
      "        [0.3209],\n",
      "        ...,\n",
      "        [0.1584],\n",
      "        [0.1280],\n",
      "        [0.1701]])\n",
      "Epoch 42 train loss: 0.4680, eval loss 0.7359389066696167\n",
      "tensor([[0.1803],\n",
      "        [0.3978],\n",
      "        [0.3247],\n",
      "        ...,\n",
      "        [0.1555],\n",
      "        [0.1237],\n",
      "        [0.1676]])\n",
      "Epoch 43 train loss: 0.4579, eval loss 0.7349414825439453\n",
      "tensor([[0.1787],\n",
      "        [0.4021],\n",
      "        [0.3289],\n",
      "        ...,\n",
      "        [0.1529],\n",
      "        [0.1197],\n",
      "        [0.1656]])\n",
      "Epoch 44 train loss: 0.4544, eval loss 0.7340357303619385\n",
      "tensor([[0.1769],\n",
      "        [0.4063],\n",
      "        [0.3330],\n",
      "        ...,\n",
      "        [0.1501],\n",
      "        [0.1156],\n",
      "        [0.1633]])\n",
      "Epoch 45 train loss: 0.4514, eval loss 0.7330909967422485\n",
      "tensor([[0.1752],\n",
      "        [0.4101],\n",
      "        [0.3373],\n",
      "        ...,\n",
      "        [0.1474],\n",
      "        [0.1116],\n",
      "        [0.1611]])\n",
      "Epoch 46 train loss: 0.4637, eval loss 0.7321640253067017\n",
      "tensor([[0.1739],\n",
      "        [0.4139],\n",
      "        [0.3421],\n",
      "        ...,\n",
      "        [0.1449],\n",
      "        [0.1079],\n",
      "        [0.1591]])\n",
      "Epoch 47 train loss: 0.4446, eval loss 0.731323778629303\n",
      "tensor([[0.1723],\n",
      "        [0.4178],\n",
      "        [0.3468],\n",
      "        ...,\n",
      "        [0.1423],\n",
      "        [0.1041],\n",
      "        [0.1570]])\n",
      "Epoch 48 train loss: 0.4496, eval loss 0.7304499745368958\n",
      "tensor([[0.1708],\n",
      "        [0.4218],\n",
      "        [0.3516],\n",
      "        ...,\n",
      "        [0.1399],\n",
      "        [0.1004],\n",
      "        [0.1550]])\n",
      "Epoch 49 train loss: 0.4519, eval loss 0.7295956611633301\n",
      "tensor([[0.1697],\n",
      "        [0.4261],\n",
      "        [0.3568],\n",
      "        ...,\n",
      "        [0.1378],\n",
      "        [0.0971],\n",
      "        [0.1533]])\n",
      "Epoch 50 train loss: 0.4447, eval loss 0.7288482189178467\n",
      "tensor([[0.1681],\n",
      "        [0.4303],\n",
      "        [0.3616],\n",
      "        ...,\n",
      "        [0.1352],\n",
      "        [0.0935],\n",
      "        [0.1512]])\n",
      "Epoch 51 train loss: 0.4540, eval loss 0.7279970645904541\n",
      "tensor([[0.1668],\n",
      "        [0.4347],\n",
      "        [0.3669],\n",
      "        ...,\n",
      "        [0.1330],\n",
      "        [0.0901],\n",
      "        [0.1493]])\n",
      "Epoch 52 train loss: 0.4271, eval loss 0.7272108793258667\n",
      "tensor([[0.1654],\n",
      "        [0.4391],\n",
      "        [0.3720],\n",
      "        ...,\n",
      "        [0.1305],\n",
      "        [0.0868],\n",
      "        [0.1473]])\n",
      "Epoch 53 train loss: 0.4286, eval loss 0.7264189720153809\n",
      "tensor([[0.1643],\n",
      "        [0.4438],\n",
      "        [0.3775],\n",
      "        ...,\n",
      "        [0.1285],\n",
      "        [0.0837],\n",
      "        [0.1456]])\n",
      "Epoch 54 train loss: 0.4389, eval loss 0.7257103323936462\n",
      "tensor([[0.1633],\n",
      "        [0.4484],\n",
      "        [0.3828],\n",
      "        ...,\n",
      "        [0.1263],\n",
      "        [0.0807],\n",
      "        [0.1438]])\n",
      "Epoch 55 train loss: 0.4298, eval loss 0.7249903678894043\n",
      "tensor([[0.1623],\n",
      "        [0.4529],\n",
      "        [0.3884],\n",
      "        ...,\n",
      "        [0.1242],\n",
      "        [0.0778],\n",
      "        [0.1422]])\n",
      "Epoch 56 train loss: 0.4406, eval loss 0.7243057489395142\n",
      "tensor([[0.1613],\n",
      "        [0.4574],\n",
      "        [0.3940],\n",
      "        ...,\n",
      "        [0.1222],\n",
      "        [0.0750],\n",
      "        [0.1405]])\n",
      "Epoch 57 train loss: 0.4395, eval loss 0.7236396670341492\n",
      "tensor([[0.1606],\n",
      "        [0.4623],\n",
      "        [0.4000],\n",
      "        ...,\n",
      "        [0.1205],\n",
      "        [0.0724],\n",
      "        [0.1391]])\n",
      "Epoch 58 train loss: 0.4219, eval loss 0.7230380773544312\n",
      "tensor([[0.1598],\n",
      "        [0.4671],\n",
      "        [0.4059],\n",
      "        ...,\n",
      "        [0.1186],\n",
      "        [0.0697],\n",
      "        [0.1376]])\n",
      "Epoch 59 train loss: 0.4311, eval loss 0.7224143743515015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1591],\n",
      "        [0.4720],\n",
      "        [0.4118],\n",
      "        ...,\n",
      "        [0.1169],\n",
      "        [0.0673],\n",
      "        [0.1362]])\n",
      "Epoch 60 train loss: 0.4335, eval loss 0.7218363285064697\n",
      "tensor([[0.1583],\n",
      "        [0.4770],\n",
      "        [0.4178],\n",
      "        ...,\n",
      "        [0.1151],\n",
      "        [0.0648],\n",
      "        [0.1347]])\n",
      "Epoch 61 train loss: 0.4345, eval loss 0.7212306261062622\n",
      "tensor([[0.1573],\n",
      "        [0.4819],\n",
      "        [0.4235],\n",
      "        ...,\n",
      "        [0.1133],\n",
      "        [0.0624],\n",
      "        [0.1332]])\n",
      "Epoch 62 train loss: 0.4104, eval loss 0.720615565776825\n",
      "tensor([[0.1563],\n",
      "        [0.4868],\n",
      "        [0.4292],\n",
      "        ...,\n",
      "        [0.1113],\n",
      "        [0.0600],\n",
      "        [0.1315]])\n",
      "Epoch 63 train loss: 0.4069, eval loss 0.7199905514717102\n",
      "tensor([[0.1559],\n",
      "        [0.4916],\n",
      "        [0.4356],\n",
      "        ...,\n",
      "        [0.1098],\n",
      "        [0.0579],\n",
      "        [0.1303]])\n",
      "Epoch 64 train loss: 0.4315, eval loss 0.7195053696632385\n",
      "tensor([[0.1552],\n",
      "        [0.4963],\n",
      "        [0.4417],\n",
      "        ...,\n",
      "        [0.1080],\n",
      "        [0.0557],\n",
      "        [0.1288]])\n",
      "Epoch 65 train loss: 0.4358, eval loss 0.7189403176307678\n",
      "tensor([[0.1544],\n",
      "        [0.5012],\n",
      "        [0.4475],\n",
      "        ...,\n",
      "        [0.1063],\n",
      "        [0.0536],\n",
      "        [0.1274]])\n",
      "Epoch 66 train loss: 0.4222, eval loss 0.7183821201324463\n",
      "tensor([[0.1538],\n",
      "        [0.5060],\n",
      "        [0.4536],\n",
      "        ...,\n",
      "        [0.1047],\n",
      "        [0.0517],\n",
      "        [0.1263]])\n",
      "Epoch 67 train loss: 0.4151, eval loss 0.7178891897201538\n",
      "tensor([[0.1531],\n",
      "        [0.5107],\n",
      "        [0.4594],\n",
      "        ...,\n",
      "        [0.1030],\n",
      "        [0.0498],\n",
      "        [0.1250]])\n",
      "Epoch 68 train loss: 0.4115, eval loss 0.7173622846603394\n",
      "tensor([[0.1526],\n",
      "        [0.5155],\n",
      "        [0.4654],\n",
      "        ...,\n",
      "        [0.1016],\n",
      "        [0.0480],\n",
      "        [0.1239]])\n",
      "Epoch 69 train loss: 0.4132, eval loss 0.7168942093849182\n",
      "tensor([[0.1520],\n",
      "        [0.5204],\n",
      "        [0.4715],\n",
      "        ...,\n",
      "        [0.1000],\n",
      "        [0.0463],\n",
      "        [0.1228]])\n",
      "Epoch 70 train loss: 0.4141, eval loss 0.7164175510406494\n",
      "tensor([[0.1512],\n",
      "        [0.5251],\n",
      "        [0.4771],\n",
      "        ...,\n",
      "        [0.0984],\n",
      "        [0.0446],\n",
      "        [0.1215]])\n",
      "Epoch 71 train loss: 0.4216, eval loss 0.7159175276756287\n",
      "tensor([[0.1504],\n",
      "        [0.5297],\n",
      "        [0.4827],\n",
      "        ...,\n",
      "        [0.0968],\n",
      "        [0.0430],\n",
      "        [0.1201]])\n",
      "Epoch 72 train loss: 0.4096, eval loss 0.7154066562652588\n",
      "tensor([[0.1500],\n",
      "        [0.5344],\n",
      "        [0.4886],\n",
      "        ...,\n",
      "        [0.0953],\n",
      "        [0.0415],\n",
      "        [0.1191]])\n",
      "Epoch 73 train loss: 0.4196, eval loss 0.7149760723114014\n",
      "tensor([[0.1495],\n",
      "        [0.5392],\n",
      "        [0.4943],\n",
      "        ...,\n",
      "        [0.0939],\n",
      "        [0.0400],\n",
      "        [0.1181]])\n",
      "Epoch 74 train loss: 0.4055, eval loss 0.7145417928695679\n",
      "tensor([[0.1490],\n",
      "        [0.5439],\n",
      "        [0.4999],\n",
      "        ...,\n",
      "        [0.0924],\n",
      "        [0.0386],\n",
      "        [0.1171]])\n",
      "Epoch 75 train loss: 0.3922, eval loss 0.7141239047050476\n",
      "tensor([[0.1483],\n",
      "        [0.5485],\n",
      "        [0.5049],\n",
      "        ...,\n",
      "        [0.0909],\n",
      "        [0.0372],\n",
      "        [0.1159]])\n",
      "Epoch 76 train loss: 0.4026, eval loss 0.7136659026145935\n",
      "tensor([[0.1479],\n",
      "        [0.5530],\n",
      "        [0.5099],\n",
      "        ...,\n",
      "        [0.0897],\n",
      "        [0.0360],\n",
      "        [0.1151]])\n",
      "Epoch 77 train loss: 0.3964, eval loss 0.7132999300956726\n",
      "tensor([[0.1473],\n",
      "        [0.5576],\n",
      "        [0.5149],\n",
      "        ...,\n",
      "        [0.0883],\n",
      "        [0.0348],\n",
      "        [0.1141]])\n",
      "Epoch 78 train loss: 0.4233, eval loss 0.7128793597221375\n",
      "tensor([[0.1469],\n",
      "        [0.5621],\n",
      "        [0.5197],\n",
      "        ...,\n",
      "        [0.0870],\n",
      "        [0.0336],\n",
      "        [0.1132]])\n",
      "Epoch 79 train loss: 0.4238, eval loss 0.7125080823898315\n",
      "tensor([[0.1466],\n",
      "        [0.5666],\n",
      "        [0.5246],\n",
      "        ...,\n",
      "        [0.0857],\n",
      "        [0.0325],\n",
      "        [0.1124]])\n",
      "Epoch 80 train loss: 0.4078, eval loss 0.7121620178222656\n",
      "tensor([[0.1461],\n",
      "        [0.5709],\n",
      "        [0.5292],\n",
      "        ...,\n",
      "        [0.0843],\n",
      "        [0.0314],\n",
      "        [0.1114]])\n",
      "Epoch 81 train loss: 0.4068, eval loss 0.7117567658424377\n",
      "tensor([[0.1455],\n",
      "        [0.5753],\n",
      "        [0.5339],\n",
      "        ...,\n",
      "        [0.0829],\n",
      "        [0.0304],\n",
      "        [0.1103]])\n",
      "Epoch 82 train loss: 0.3896, eval loss 0.7113654017448425\n",
      "tensor([[0.1449],\n",
      "        [0.5794],\n",
      "        [0.5382],\n",
      "        ...,\n",
      "        [0.0816],\n",
      "        [0.0294],\n",
      "        [0.1093]])\n",
      "Epoch 83 train loss: 0.4174, eval loss 0.7109835147857666\n",
      "tensor([[0.1444],\n",
      "        [0.5835],\n",
      "        [0.5426],\n",
      "        ...,\n",
      "        [0.0805],\n",
      "        [0.0285],\n",
      "        [0.1085]])\n",
      "Epoch 84 train loss: 0.4145, eval loss 0.710648238658905\n",
      "tensor([[0.1440],\n",
      "        [0.5872],\n",
      "        [0.5468],\n",
      "        ...,\n",
      "        [0.0794],\n",
      "        [0.0276],\n",
      "        [0.1078]])\n",
      "Epoch 85 train loss: 0.3969, eval loss 0.7103273868560791\n",
      "tensor([[0.1434],\n",
      "        [0.5912],\n",
      "        [0.5509],\n",
      "        ...,\n",
      "        [0.0782],\n",
      "        [0.0267],\n",
      "        [0.1069]])\n",
      "Epoch 86 train loss: 0.4066, eval loss 0.7099687457084656\n",
      "tensor([[0.1431],\n",
      "        [0.5949],\n",
      "        [0.5549],\n",
      "        ...,\n",
      "        [0.0772],\n",
      "        [0.0260],\n",
      "        [0.1061]])\n",
      "Epoch 87 train loss: 0.4025, eval loss 0.7096590399742126\n",
      "tensor([[0.1428],\n",
      "        [0.5985],\n",
      "        [0.5591],\n",
      "        ...,\n",
      "        [0.0762],\n",
      "        [0.0253],\n",
      "        [0.1055]])\n",
      "Epoch 88 train loss: 0.4221, eval loss 0.7093765735626221\n",
      "tensor([[0.1423],\n",
      "        [0.6022],\n",
      "        [0.5630],\n",
      "        ...,\n",
      "        [0.0751],\n",
      "        [0.0245],\n",
      "        [0.1046]])\n",
      "Epoch 89 train loss: 0.3965, eval loss 0.7090458273887634\n",
      "tensor([[0.1418],\n",
      "        [0.6056],\n",
      "        [0.5668],\n",
      "        ...,\n",
      "        [0.0742],\n",
      "        [0.0239],\n",
      "        [0.1039]])\n",
      "Epoch 90 train loss: 0.3986, eval loss 0.7087557911872864\n",
      "tensor([[0.1414],\n",
      "        [0.6090],\n",
      "        [0.5705],\n",
      "        ...,\n",
      "        [0.0731],\n",
      "        [0.0232],\n",
      "        [0.1031]])\n",
      "Epoch 91 train loss: 0.4011, eval loss 0.7084729075431824\n",
      "tensor([[0.1410],\n",
      "        [0.6120],\n",
      "        [0.5739],\n",
      "        ...,\n",
      "        [0.0720],\n",
      "        [0.0226],\n",
      "        [0.1023]])\n",
      "Epoch 92 train loss: 0.4279, eval loss 0.7081751823425293\n",
      "tensor([[0.1407],\n",
      "        [0.6152],\n",
      "        [0.5775],\n",
      "        ...,\n",
      "        [0.0711],\n",
      "        [0.0220],\n",
      "        [0.1017]])\n",
      "Epoch 93 train loss: 0.4400, eval loss 0.7079248428344727\n",
      "tensor([[0.1404],\n",
      "        [0.6183],\n",
      "        [0.5808],\n",
      "        ...,\n",
      "        [0.0702],\n",
      "        [0.0215],\n",
      "        [0.1011]])\n",
      "Epoch 94 train loss: 0.3992, eval loss 0.7076802849769592\n",
      "tensor([[0.1400],\n",
      "        [0.6213],\n",
      "        [0.5841],\n",
      "        ...,\n",
      "        [0.0693],\n",
      "        [0.0209],\n",
      "        [0.1004]])\n",
      "Epoch 95 train loss: 0.3766, eval loss 0.707428514957428\n",
      "tensor([[0.1397],\n",
      "        [0.6243],\n",
      "        [0.5874],\n",
      "        ...,\n",
      "        [0.0685],\n",
      "        [0.0204],\n",
      "        [0.0998]])\n",
      "Epoch 96 train loss: 0.4039, eval loss 0.7071910500526428\n",
      "tensor([[0.1395],\n",
      "        [0.6272],\n",
      "        [0.5906],\n",
      "        ...,\n",
      "        [0.0677],\n",
      "        [0.0200],\n",
      "        [0.0993]])\n",
      "Epoch 97 train loss: 0.4088, eval loss 0.706969678401947\n",
      "tensor([[0.1391],\n",
      "        [0.6301],\n",
      "        [0.5938],\n",
      "        ...,\n",
      "        [0.0669],\n",
      "        [0.0195],\n",
      "        [0.0987]])\n",
      "Epoch 98 train loss: 0.3748, eval loss 0.7067275047302246\n",
      "tensor([[0.1387],\n",
      "        [0.6327],\n",
      "        [0.5968],\n",
      "        ...,\n",
      "        [0.0660],\n",
      "        [0.0191],\n",
      "        [0.0980]])\n",
      "Epoch 99 train loss: 0.3819, eval loss 0.7064746022224426\n",
      "tensor([[0.1384],\n",
      "        [0.6350],\n",
      "        [0.5995],\n",
      "        ...,\n",
      "        [0.0652],\n",
      "        [0.0187],\n",
      "        [0.0974]])\n",
      "Epoch 100 train loss: 0.3817, eval loss 0.7062397599220276\n",
      "tensor([[0.1377],\n",
      "        [0.6378],\n",
      "        [0.6023],\n",
      "        ...,\n",
      "        [0.0644],\n",
      "        [0.0182],\n",
      "        [0.0966]])\n",
      "Epoch 101 train loss: 0.3888, eval loss 0.7059654593467712\n",
      "tensor([[0.1376],\n",
      "        [0.6403],\n",
      "        [0.6051],\n",
      "        ...,\n",
      "        [0.0637],\n",
      "        [0.0179],\n",
      "        [0.0963]])\n",
      "Epoch 102 train loss: 0.3812, eval loss 0.7057988047599792\n",
      "tensor([[0.1374],\n",
      "        [0.6426],\n",
      "        [0.6078],\n",
      "        ...,\n",
      "        [0.0631],\n",
      "        [0.0175],\n",
      "        [0.0958]])\n",
      "Epoch 103 train loss: 0.3859, eval loss 0.7056032419204712\n",
      "tensor([[0.1370],\n",
      "        [0.6452],\n",
      "        [0.6106],\n",
      "        ...,\n",
      "        [0.0623],\n",
      "        [0.0172],\n",
      "        [0.0952]])\n",
      "Epoch 104 train loss: 0.4069, eval loss 0.7053800821304321\n",
      "tensor([[0.1367],\n",
      "        [0.6473],\n",
      "        [0.6129],\n",
      "        ...,\n",
      "        [0.0616],\n",
      "        [0.0168],\n",
      "        [0.0947]])\n",
      "Epoch 105 train loss: 0.4065, eval loss 0.7051741480827332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1365],\n",
      "        [0.6495],\n",
      "        [0.6153],\n",
      "        ...,\n",
      "        [0.0610],\n",
      "        [0.0165],\n",
      "        [0.0943]])\n",
      "Epoch 106 train loss: 0.3668, eval loss 0.7049964070320129\n",
      "tensor([[0.1362],\n",
      "        [0.6514],\n",
      "        [0.6174],\n",
      "        ...,\n",
      "        [0.0604],\n",
      "        [0.0162],\n",
      "        [0.0938]])\n",
      "Epoch 107 train loss: 0.4037, eval loss 0.7048006057739258\n",
      "tensor([[0.1360],\n",
      "        [0.6534],\n",
      "        [0.6197],\n",
      "        ...,\n",
      "        [0.0598],\n",
      "        [0.0160],\n",
      "        [0.0934]])\n",
      "Epoch 108 train loss: 0.3805, eval loss 0.7046384215354919\n",
      "tensor([[0.1357],\n",
      "        [0.6554],\n",
      "        [0.6218],\n",
      "        ...,\n",
      "        [0.0592],\n",
      "        [0.0157],\n",
      "        [0.0931]])\n",
      "Epoch 109 train loss: 0.3867, eval loss 0.7044739723205566\n",
      "tensor([[0.1354],\n",
      "        [0.6574],\n",
      "        [0.6239],\n",
      "        ...,\n",
      "        [0.0586],\n",
      "        [0.0154],\n",
      "        [0.0926]])\n",
      "Epoch 110 train loss: 0.4214, eval loss 0.7043026089668274\n",
      "tensor([[0.1356],\n",
      "        [0.6593],\n",
      "        [0.6262],\n",
      "        ...,\n",
      "        [0.0582],\n",
      "        [0.0152],\n",
      "        [0.0925]])\n",
      "Epoch 111 train loss: 0.3959, eval loss 0.7042035460472107\n",
      "tensor([[0.1353],\n",
      "        [0.6609],\n",
      "        [0.6281],\n",
      "        ...,\n",
      "        [0.0576],\n",
      "        [0.0150],\n",
      "        [0.0920]])\n",
      "Epoch 112 train loss: 0.3950, eval loss 0.7040461301803589\n",
      "tensor([[0.1347],\n",
      "        [0.6624],\n",
      "        [0.6296],\n",
      "        ...,\n",
      "        [0.0568],\n",
      "        [0.0147],\n",
      "        [0.0913]])\n",
      "Epoch 113 train loss: 0.4146, eval loss 0.7038046717643738\n",
      "tensor([[0.1344],\n",
      "        [0.6641],\n",
      "        [0.6315],\n",
      "        ...,\n",
      "        [0.0563],\n",
      "        [0.0145],\n",
      "        [0.0909]])\n",
      "Epoch 114 train loss: 0.3631, eval loss 0.7036468982696533\n",
      "tensor([[0.1342],\n",
      "        [0.6659],\n",
      "        [0.6335],\n",
      "        ...,\n",
      "        [0.0558],\n",
      "        [0.0143],\n",
      "        [0.0906]])\n",
      "Epoch 115 train loss: 0.4082, eval loss 0.7035052180290222\n",
      "tensor([[0.1341],\n",
      "        [0.6676],\n",
      "        [0.6354],\n",
      "        ...,\n",
      "        [0.0554],\n",
      "        [0.0141],\n",
      "        [0.0904]])\n",
      "Epoch 116 train loss: 0.4006, eval loss 0.703388512134552\n",
      "tensor([[0.1342],\n",
      "        [0.6693],\n",
      "        [0.6373],\n",
      "        ...,\n",
      "        [0.0551],\n",
      "        [0.0140],\n",
      "        [0.0902]])\n",
      "Epoch 117 train loss: 0.4090, eval loss 0.7032805681228638\n",
      "tensor([[0.1337],\n",
      "        [0.6706],\n",
      "        [0.6388],\n",
      "        ...,\n",
      "        [0.0546],\n",
      "        [0.0138],\n",
      "        [0.0897]])\n",
      "Epoch 118 train loss: 0.3916, eval loss 0.7030985951423645\n",
      "tensor([[0.1331],\n",
      "        [0.6718],\n",
      "        [0.6401],\n",
      "        ...,\n",
      "        [0.0540],\n",
      "        [0.0136],\n",
      "        [0.0892]])\n",
      "Epoch 119 train loss: 0.3645, eval loss 0.7028980255126953\n",
      "tensor([[0.1328],\n",
      "        [0.6734],\n",
      "        [0.6419],\n",
      "        ...,\n",
      "        [0.0536],\n",
      "        [0.0134],\n",
      "        [0.0888]])\n",
      "Epoch 120 train loss: 0.4053, eval loss 0.702760636806488\n",
      "tensor([[0.1326],\n",
      "        [0.6749],\n",
      "        [0.6436],\n",
      "        ...,\n",
      "        [0.0530],\n",
      "        [0.0132],\n",
      "        [0.0884]])\n",
      "Epoch 121 train loss: 0.3801, eval loss 0.7025949358940125\n",
      "tensor([[0.1319],\n",
      "        [0.6760],\n",
      "        [0.6448],\n",
      "        ...,\n",
      "        [0.0524],\n",
      "        [0.0130],\n",
      "        [0.0877]])\n",
      "Epoch 122 train loss: 0.3819, eval loss 0.7023876309394836\n",
      "tensor([[0.1318],\n",
      "        [0.6773],\n",
      "        [0.6464],\n",
      "        ...,\n",
      "        [0.0520],\n",
      "        [0.0129],\n",
      "        [0.0874]])\n",
      "Epoch 123 train loss: 0.3816, eval loss 0.7022941708564758\n",
      "tensor([[0.1315],\n",
      "        [0.6786],\n",
      "        [0.6479],\n",
      "        ...,\n",
      "        [0.0516],\n",
      "        [0.0127],\n",
      "        [0.0871]])\n",
      "Epoch 124 train loss: 0.3961, eval loss 0.7021448016166687\n",
      "tensor([[0.1312],\n",
      "        [0.6796],\n",
      "        [0.6490],\n",
      "        ...,\n",
      "        [0.0512],\n",
      "        [0.0126],\n",
      "        [0.0868]])\n",
      "Epoch 125 train loss: 0.3910, eval loss 0.7019925713539124\n",
      "tensor([[0.1314],\n",
      "        [0.6809],\n",
      "        [0.6506],\n",
      "        ...,\n",
      "        [0.0509],\n",
      "        [0.0125],\n",
      "        [0.0868]])\n",
      "Epoch 126 train loss: 0.4000, eval loss 0.7019267678260803\n",
      "tensor([[0.1309],\n",
      "        [0.6819],\n",
      "        [0.6518],\n",
      "        ...,\n",
      "        [0.0504],\n",
      "        [0.0123],\n",
      "        [0.0862]])\n",
      "Epoch 127 train loss: 0.3774, eval loss 0.7017599940299988\n",
      "tensor([[0.1306],\n",
      "        [0.6829],\n",
      "        [0.6529],\n",
      "        ...,\n",
      "        [0.0500],\n",
      "        [0.0122],\n",
      "        [0.0858]])\n",
      "Epoch 128 train loss: 0.3763, eval loss 0.7016082406044006\n",
      "tensor([[0.1304],\n",
      "        [0.6836],\n",
      "        [0.6538],\n",
      "        ...,\n",
      "        [0.0497],\n",
      "        [0.0121],\n",
      "        [0.0856]])\n",
      "Epoch 129 train loss: 0.4269, eval loss 0.7014982104301453\n",
      "tensor([[0.1307],\n",
      "        [0.6849],\n",
      "        [0.6553],\n",
      "        ...,\n",
      "        [0.0496],\n",
      "        [0.0120],\n",
      "        [0.0858]])\n",
      "Epoch 130 train loss: 0.3868, eval loss 0.701470673084259\n",
      "tensor([[0.1306],\n",
      "        [0.6862],\n",
      "        [0.6566],\n",
      "        ...,\n",
      "        [0.0493],\n",
      "        [0.0119],\n",
      "        [0.0856]])\n",
      "Epoch 131 train loss: 0.3880, eval loss 0.7013741135597229\n",
      "tensor([[0.1301],\n",
      "        [0.6872],\n",
      "        [0.6577],\n",
      "        ...,\n",
      "        [0.0489],\n",
      "        [0.0118],\n",
      "        [0.0852]])\n",
      "Epoch 132 train loss: 0.3977, eval loss 0.7012212872505188\n",
      "tensor([[0.1299],\n",
      "        [0.6884],\n",
      "        [0.6592],\n",
      "        ...,\n",
      "        [0.0485],\n",
      "        [0.0117],\n",
      "        [0.0849]])\n",
      "Epoch 133 train loss: 0.4010, eval loss 0.7011160850524902\n",
      "tensor([[0.1294],\n",
      "        [0.6893],\n",
      "        [0.6602],\n",
      "        ...,\n",
      "        [0.0480],\n",
      "        [0.0116],\n",
      "        [0.0844]])\n",
      "Epoch 134 train loss: 0.3746, eval loss 0.7009605169296265\n",
      "tensor([[0.1288],\n",
      "        [0.6903],\n",
      "        [0.6614],\n",
      "        ...,\n",
      "        [0.0476],\n",
      "        [0.0114],\n",
      "        [0.0840]])\n",
      "Epoch 135 train loss: 0.3980, eval loss 0.700796365737915\n",
      "tensor([[0.1290],\n",
      "        [0.6915],\n",
      "        [0.6629],\n",
      "        ...,\n",
      "        [0.0474],\n",
      "        [0.0113],\n",
      "        [0.0841]])\n",
      "Epoch 136 train loss: 0.3935, eval loss 0.7007712721824646\n",
      "tensor([[0.1288],\n",
      "        [0.6924],\n",
      "        [0.6640],\n",
      "        ...,\n",
      "        [0.0471],\n",
      "        [0.0113],\n",
      "        [0.0839]])\n",
      "Epoch 137 train loss: 0.3929, eval loss 0.7006840109825134\n",
      "tensor([[0.1283],\n",
      "        [0.6934],\n",
      "        [0.6651],\n",
      "        ...,\n",
      "        [0.0469],\n",
      "        [0.0112],\n",
      "        [0.0836]])\n",
      "Epoch 138 train loss: 0.4110, eval loss 0.7005735039710999\n",
      "tensor([[0.1279],\n",
      "        [0.6938],\n",
      "        [0.6658],\n",
      "        ...,\n",
      "        [0.0465],\n",
      "        [0.0111],\n",
      "        [0.0831]])\n",
      "Epoch 139 train loss: 0.3955, eval loss 0.7004298567771912\n",
      "tensor([[0.1275],\n",
      "        [0.6947],\n",
      "        [0.6668],\n",
      "        ...,\n",
      "        [0.0461],\n",
      "        [0.0110],\n",
      "        [0.0827]])\n",
      "Epoch 140 train loss: 0.3754, eval loss 0.70030277967453\n",
      "tensor([[0.1271],\n",
      "        [0.6954],\n",
      "        [0.6678],\n",
      "        ...,\n",
      "        [0.0457],\n",
      "        [0.0109],\n",
      "        [0.0824]])\n",
      "Epoch 141 train loss: 0.3578, eval loss 0.7001692056655884\n",
      "tensor([[0.1268],\n",
      "        [0.6962],\n",
      "        [0.6687],\n",
      "        ...,\n",
      "        [0.0455],\n",
      "        [0.0108],\n",
      "        [0.0822]])\n",
      "Epoch 142 train loss: 0.3841, eval loss 0.7000768184661865\n",
      "tensor([[0.1264],\n",
      "        [0.6970],\n",
      "        [0.6696],\n",
      "        ...,\n",
      "        [0.0452],\n",
      "        [0.0107],\n",
      "        [0.0819]])\n",
      "Epoch 143 train loss: 0.3907, eval loss 0.6999559998512268\n",
      "tensor([[0.1261],\n",
      "        [0.6979],\n",
      "        [0.6706],\n",
      "        ...,\n",
      "        [0.0450],\n",
      "        [0.0106],\n",
      "        [0.0817]])\n",
      "Epoch 144 train loss: 0.3814, eval loss 0.6998538374900818\n",
      "tensor([[0.1263],\n",
      "        [0.6991],\n",
      "        [0.6721],\n",
      "        ...,\n",
      "        [0.0448],\n",
      "        [0.0106],\n",
      "        [0.0817]])\n",
      "Epoch 145 train loss: 0.4032, eval loss 0.699827253818512\n",
      "tensor([[0.1261],\n",
      "        [0.6998],\n",
      "        [0.6731],\n",
      "        ...,\n",
      "        [0.0446],\n",
      "        [0.0105],\n",
      "        [0.0816]])\n",
      "Epoch 146 train loss: 0.3897, eval loss 0.6997402906417847\n",
      "tensor([[0.1261],\n",
      "        [0.7009],\n",
      "        [0.6743],\n",
      "        ...,\n",
      "        [0.0444],\n",
      "        [0.0105],\n",
      "        [0.0816]])\n",
      "Epoch 147 train loss: 0.3727, eval loss 0.6996920704841614\n",
      "tensor([[0.1261],\n",
      "        [0.7014],\n",
      "        [0.6750],\n",
      "        ...,\n",
      "        [0.0443],\n",
      "        [0.0104],\n",
      "        [0.0816]])\n",
      "Epoch 148 train loss: 0.3647, eval loss 0.6996489763259888\n",
      "tensor([[0.1259],\n",
      "        [0.7022],\n",
      "        [0.6759],\n",
      "        ...,\n",
      "        [0.0442],\n",
      "        [0.0104],\n",
      "        [0.0815]])\n",
      "Epoch 149 train loss: 0.3793, eval loss 0.699572741985321\n",
      "tensor([[0.1256],\n",
      "        [0.7028],\n",
      "        [0.6768],\n",
      "        ...,\n",
      "        [0.0440],\n",
      "        [0.0103],\n",
      "        [0.0814]])\n",
      "Epoch 150 train loss: 0.3961, eval loss 0.6994971036911011\n",
      "tensor([[0.1253],\n",
      "        [0.7035],\n",
      "        [0.6776],\n",
      "        ...,\n",
      "        [0.0438],\n",
      "        [0.0103],\n",
      "        [0.0812]])\n",
      "Epoch 151 train loss: 0.4134, eval loss 0.6994158625602722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1253],\n",
      "        [0.7044],\n",
      "        [0.6787],\n",
      "        ...,\n",
      "        [0.0438],\n",
      "        [0.0102],\n",
      "        [0.0812]])\n",
      "Epoch 152 train loss: 0.3552, eval loss 0.699370265007019\n",
      "tensor([[0.1247],\n",
      "        [0.7051],\n",
      "        [0.6795],\n",
      "        ...,\n",
      "        [0.0435],\n",
      "        [0.0101],\n",
      "        [0.0808]])\n",
      "Epoch 153 train loss: 0.4091, eval loss 0.6992247700691223\n",
      "tensor([[0.1243],\n",
      "        [0.7058],\n",
      "        [0.6804],\n",
      "        ...,\n",
      "        [0.0432],\n",
      "        [0.0101],\n",
      "        [0.0805]])\n",
      "Epoch 154 train loss: 0.4104, eval loss 0.6991255283355713\n",
      "tensor([[0.1239],\n",
      "        [0.7063],\n",
      "        [0.6811],\n",
      "        ...,\n",
      "        [0.0430],\n",
      "        [0.0100],\n",
      "        [0.0802]])\n",
      "Epoch 155 train loss: 0.3877, eval loss 0.6990174651145935\n",
      "tensor([[0.1236],\n",
      "        [0.7071],\n",
      "        [0.6819],\n",
      "        ...,\n",
      "        [0.0429],\n",
      "        [0.0099],\n",
      "        [0.0801]])\n",
      "Epoch 156 train loss: 0.3621, eval loss 0.69894939661026\n",
      "tensor([[0.1234],\n",
      "        [0.7078],\n",
      "        [0.6826],\n",
      "        ...,\n",
      "        [0.0429],\n",
      "        [0.0099],\n",
      "        [0.0801]])\n",
      "Epoch 157 train loss: 0.4213, eval loss 0.6988982558250427\n",
      "tensor([[0.1234],\n",
      "        [0.7083],\n",
      "        [0.6834],\n",
      "        ...,\n",
      "        [0.0427],\n",
      "        [0.0099],\n",
      "        [0.0800]])\n",
      "Epoch 158 train loss: 0.3988, eval loss 0.6988401412963867\n",
      "tensor([[0.1233],\n",
      "        [0.7088],\n",
      "        [0.6842],\n",
      "        ...,\n",
      "        [0.0424],\n",
      "        [0.0098],\n",
      "        [0.0799]])\n",
      "Epoch 159 train loss: 0.4236, eval loss 0.6987956762313843\n",
      "tensor([[0.1228],\n",
      "        [0.7094],\n",
      "        [0.6848],\n",
      "        ...,\n",
      "        [0.0422],\n",
      "        [0.0098],\n",
      "        [0.0795]])\n",
      "Epoch 160 train loss: 0.3680, eval loss 0.6986907124519348\n",
      "tensor([[0.1221],\n",
      "        [0.7099],\n",
      "        [0.6855],\n",
      "        ...,\n",
      "        [0.0420],\n",
      "        [0.0097],\n",
      "        [0.0792]])\n",
      "Epoch 161 train loss: 0.4139, eval loss 0.6985573768615723\n",
      "tensor([[0.1219],\n",
      "        [0.7102],\n",
      "        [0.6860],\n",
      "        ...,\n",
      "        [0.0418],\n",
      "        [0.0096],\n",
      "        [0.0791]])\n",
      "Epoch 162 train loss: 0.3785, eval loss 0.6984769105911255\n",
      "tensor([[0.1216],\n",
      "        [0.7107],\n",
      "        [0.6867],\n",
      "        ...,\n",
      "        [0.0417],\n",
      "        [0.0096],\n",
      "        [0.0790]])\n",
      "Epoch 163 train loss: 0.3500, eval loss 0.6984029412269592\n",
      "tensor([[0.1218],\n",
      "        [0.7114],\n",
      "        [0.6876],\n",
      "        ...,\n",
      "        [0.0418],\n",
      "        [0.0096],\n",
      "        [0.0793]])\n",
      "Epoch 164 train loss: 0.3685, eval loss 0.6984030604362488\n",
      "tensor([[0.1218],\n",
      "        [0.7119],\n",
      "        [0.6883],\n",
      "        ...,\n",
      "        [0.0417],\n",
      "        [0.0095],\n",
      "        [0.0794]])\n",
      "Epoch 165 train loss: 0.3991, eval loss 0.6983596086502075\n",
      "tensor([[0.1217],\n",
      "        [0.7126],\n",
      "        [0.6891],\n",
      "        ...,\n",
      "        [0.0417],\n",
      "        [0.0095],\n",
      "        [0.0795]])\n",
      "Epoch 166 train loss: 0.3722, eval loss 0.69834965467453\n",
      "tensor([[0.1210],\n",
      "        [0.7129],\n",
      "        [0.6894],\n",
      "        ...,\n",
      "        [0.0415],\n",
      "        [0.0094],\n",
      "        [0.0792]])\n",
      "Epoch 167 train loss: 0.3827, eval loss 0.698226273059845\n",
      "tensor([[0.1204],\n",
      "        [0.7136],\n",
      "        [0.6901],\n",
      "        ...,\n",
      "        [0.0414],\n",
      "        [0.0094],\n",
      "        [0.0790]])\n",
      "Epoch 168 train loss: 0.3864, eval loss 0.6981548070907593\n",
      "tensor([[0.1202],\n",
      "        [0.7138],\n",
      "        [0.6904],\n",
      "        ...,\n",
      "        [0.0414],\n",
      "        [0.0094],\n",
      "        [0.0790]])\n",
      "Epoch 169 train loss: 0.3839, eval loss 0.6981095671653748\n",
      "tensor([[0.1200],\n",
      "        [0.7143],\n",
      "        [0.6911],\n",
      "        ...,\n",
      "        [0.0413],\n",
      "        [0.0093],\n",
      "        [0.0789]])\n",
      "Epoch 170 train loss: 0.3880, eval loss 0.6980616450309753\n",
      "tensor([[0.1198],\n",
      "        [0.7150],\n",
      "        [0.6918],\n",
      "        ...,\n",
      "        [0.0413],\n",
      "        [0.0093],\n",
      "        [0.0790]])\n",
      "Epoch 171 train loss: 0.4004, eval loss 0.6980189681053162\n",
      "tensor([[0.1200],\n",
      "        [0.7154],\n",
      "        [0.6925],\n",
      "        ...,\n",
      "        [0.0413],\n",
      "        [0.0093],\n",
      "        [0.0792]])\n",
      "Epoch 172 train loss: 0.4104, eval loss 0.6980099678039551\n",
      "tensor([[0.1196],\n",
      "        [0.7159],\n",
      "        [0.6931],\n",
      "        ...,\n",
      "        [0.0412],\n",
      "        [0.0092],\n",
      "        [0.0791]])\n",
      "Epoch 173 train loss: 0.3577, eval loss 0.6979455947875977\n",
      "tensor([[0.1195],\n",
      "        [0.7166],\n",
      "        [0.6940],\n",
      "        ...,\n",
      "        [0.0412],\n",
      "        [0.0092],\n",
      "        [0.0792]])\n",
      "Epoch 174 train loss: 0.3915, eval loss 0.6979120373725891\n",
      "tensor([[0.1194],\n",
      "        [0.7170],\n",
      "        [0.6945],\n",
      "        ...,\n",
      "        [0.0411],\n",
      "        [0.0092],\n",
      "        [0.0792]])\n",
      "Epoch 175 train loss: 0.3833, eval loss 0.6978870630264282\n",
      "tensor([[0.1189],\n",
      "        [0.7175],\n",
      "        [0.6951],\n",
      "        ...,\n",
      "        [0.0410],\n",
      "        [0.0092],\n",
      "        [0.0790]])\n",
      "Epoch 176 train loss: 0.3888, eval loss 0.6978251934051514\n",
      "tensor([[0.1180],\n",
      "        [0.7175],\n",
      "        [0.6951],\n",
      "        ...,\n",
      "        [0.0407],\n",
      "        [0.0091],\n",
      "        [0.0785]])\n",
      "Epoch 177 train loss: 0.3970, eval loss 0.6976667642593384\n",
      "tensor([[0.1177],\n",
      "        [0.7180],\n",
      "        [0.6958],\n",
      "        ...,\n",
      "        [0.0407],\n",
      "        [0.0091],\n",
      "        [0.0785]])\n",
      "Epoch 178 train loss: 0.3749, eval loss 0.6976100206375122\n",
      "tensor([[0.1170],\n",
      "        [0.7187],\n",
      "        [0.6967],\n",
      "        ...,\n",
      "        [0.0404],\n",
      "        [0.0090],\n",
      "        [0.0781]])\n",
      "Epoch 179 train loss: 0.3627, eval loss 0.697470486164093\n",
      "tensor([[0.1165],\n",
      "        [0.7191],\n",
      "        [0.6971],\n",
      "        ...,\n",
      "        [0.0402],\n",
      "        [0.0089],\n",
      "        [0.0778]])\n",
      "Epoch 180 train loss: 0.3535, eval loss 0.6973633170127869\n",
      "tensor([[0.1163],\n",
      "        [0.7197],\n",
      "        [0.6978],\n",
      "        ...,\n",
      "        [0.0400],\n",
      "        [0.0089],\n",
      "        [0.0777]])\n",
      "Epoch 181 train loss: 0.3834, eval loss 0.6973069310188293\n",
      "tensor([[0.1162],\n",
      "        [0.7200],\n",
      "        [0.6984],\n",
      "        ...,\n",
      "        [0.0400],\n",
      "        [0.0089],\n",
      "        [0.0778]])\n",
      "Epoch 182 train loss: 0.4002, eval loss 0.697276771068573\n",
      "tensor([[0.1160],\n",
      "        [0.7203],\n",
      "        [0.6988],\n",
      "        ...,\n",
      "        [0.0401],\n",
      "        [0.0089],\n",
      "        [0.0780]])\n",
      "Epoch 183 train loss: 0.3959, eval loss 0.6972622275352478\n",
      "tensor([[0.1154],\n",
      "        [0.7208],\n",
      "        [0.6993],\n",
      "        ...,\n",
      "        [0.0400],\n",
      "        [0.0088],\n",
      "        [0.0778]])\n",
      "Epoch 184 train loss: 0.3891, eval loss 0.6971639394760132\n",
      "tensor([[0.1150],\n",
      "        [0.7213],\n",
      "        [0.7000],\n",
      "        ...,\n",
      "        [0.0399],\n",
      "        [0.0088],\n",
      "        [0.0777]])\n",
      "Epoch 185 train loss: 0.3882, eval loss 0.6971114277839661\n",
      "tensor([[0.1146],\n",
      "        [0.7215],\n",
      "        [0.7002],\n",
      "        ...,\n",
      "        [0.0399],\n",
      "        [0.0087],\n",
      "        [0.0777]])\n",
      "Epoch 186 train loss: 0.3805, eval loss 0.6970468163490295\n",
      "tensor([[0.1144],\n",
      "        [0.7220],\n",
      "        [0.7007],\n",
      "        ...,\n",
      "        [0.0399],\n",
      "        [0.0087],\n",
      "        [0.0777]])\n",
      "Epoch 187 train loss: 0.3888, eval loss 0.6970255374908447\n",
      "tensor([[0.1144],\n",
      "        [0.7225],\n",
      "        [0.7013],\n",
      "        ...,\n",
      "        [0.0399],\n",
      "        [0.0087],\n",
      "        [0.0778]])\n",
      "Epoch 188 train loss: 0.3749, eval loss 0.6970301866531372\n",
      "tensor([[0.1136],\n",
      "        [0.7225],\n",
      "        [0.7013],\n",
      "        ...,\n",
      "        [0.0397],\n",
      "        [0.0087],\n",
      "        [0.0774]])\n",
      "Epoch 189 train loss: 0.3846, eval loss 0.6969037652015686\n",
      "tensor([[0.1130],\n",
      "        [0.7231],\n",
      "        [0.7018],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0086],\n",
      "        [0.0772]])\n",
      "Epoch 190 train loss: 0.3741, eval loss 0.6968291997909546\n",
      "tensor([[0.1126],\n",
      "        [0.7237],\n",
      "        [0.7024],\n",
      "        ...,\n",
      "        [0.0395],\n",
      "        [0.0086],\n",
      "        [0.0770]])\n",
      "Epoch 191 train loss: 0.3864, eval loss 0.6967613101005554\n",
      "tensor([[0.1125],\n",
      "        [0.7241],\n",
      "        [0.7029],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0086],\n",
      "        [0.0771]])\n",
      "Epoch 192 train loss: 0.3755, eval loss 0.6967490315437317\n",
      "tensor([[0.1120],\n",
      "        [0.7245],\n",
      "        [0.7034],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0085],\n",
      "        [0.0771]])\n",
      "Epoch 193 train loss: 0.4043, eval loss 0.6966742873191833\n",
      "tensor([[0.1116],\n",
      "        [0.7250],\n",
      "        [0.7040],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0085],\n",
      "        [0.0771]])\n",
      "Epoch 194 train loss: 0.3875, eval loss 0.6966181397438049\n",
      "tensor([[0.1116],\n",
      "        [0.7258],\n",
      "        [0.7050],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0085],\n",
      "        [0.0773]])\n",
      "Epoch 195 train loss: 0.3554, eval loss 0.6966143846511841\n",
      "tensor([[0.1113],\n",
      "        [0.7261],\n",
      "        [0.7053],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0084],\n",
      "        [0.0772]])\n",
      "Epoch 196 train loss: 0.3563, eval loss 0.6965560913085938\n",
      "tensor([[0.1113],\n",
      "        [0.7266],\n",
      "        [0.7059],\n",
      "        ...,\n",
      "        [0.0397],\n",
      "        [0.0084],\n",
      "        [0.0774]])\n",
      "Epoch 197 train loss: 0.3731, eval loss 0.6965596675872803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1105],\n",
      "        [0.7267],\n",
      "        [0.7060],\n",
      "        ...,\n",
      "        [0.0395],\n",
      "        [0.0084],\n",
      "        [0.0770]])\n",
      "Epoch 198 train loss: 0.3701, eval loss 0.6964489221572876\n",
      "tensor([[0.1103],\n",
      "        [0.7272],\n",
      "        [0.7066],\n",
      "        ...,\n",
      "        [0.0395],\n",
      "        [0.0084],\n",
      "        [0.0770]])\n",
      "Epoch 199 train loss: 0.3517, eval loss 0.6964303851127625\n",
      "tensor([[0.1104],\n",
      "        [0.7279],\n",
      "        [0.7074],\n",
      "        ...,\n",
      "        [0.0396],\n",
      "        [0.0083],\n",
      "        [0.0773]])\n",
      "Epoch 200 train loss: 0.3698, eval loss 0.6964674592018127\n",
      "tensor([[0.1097],\n",
      "        [0.7283],\n",
      "        [0.7077],\n",
      "        ...,\n",
      "        [0.0394],\n",
      "        [0.0083],\n",
      "        [0.0770]])\n",
      "Epoch 201 train loss: 0.3684, eval loss 0.6963641047477722\n",
      "tensor([[0.1092],\n",
      "        [0.7287],\n",
      "        [0.7080],\n",
      "        ...,\n",
      "        [0.0394],\n",
      "        [0.0083],\n",
      "        [0.0769]])\n",
      "Epoch 202 train loss: 0.3863, eval loss 0.696304440498352\n",
      "tensor([[0.1085],\n",
      "        [0.7290],\n",
      "        [0.7083],\n",
      "        ...,\n",
      "        [0.0392],\n",
      "        [0.0082],\n",
      "        [0.0765]])\n",
      "Epoch 203 train loss: 0.3703, eval loss 0.6961873173713684\n",
      "tensor([[0.1081],\n",
      "        [0.7292],\n",
      "        [0.7086],\n",
      "        ...,\n",
      "        [0.0391],\n",
      "        [0.0082],\n",
      "        [0.0764]])\n",
      "Epoch 204 train loss: 0.3599, eval loss 0.6961246728897095\n",
      "tensor([[0.1079],\n",
      "        [0.7298],\n",
      "        [0.7091],\n",
      "        ...,\n",
      "        [0.0392],\n",
      "        [0.0082],\n",
      "        [0.0766]])\n",
      "Epoch 205 train loss: 0.3625, eval loss 0.6961211562156677\n",
      "tensor([[0.1073],\n",
      "        [0.7303],\n",
      "        [0.7096],\n",
      "        ...,\n",
      "        [0.0391],\n",
      "        [0.0081],\n",
      "        [0.0765]])\n",
      "Epoch 206 train loss: 0.3828, eval loss 0.6960622072219849\n",
      "tensor([[0.1065],\n",
      "        [0.7305],\n",
      "        [0.7098],\n",
      "        ...,\n",
      "        [0.0389],\n",
      "        [0.0081],\n",
      "        [0.0761]])\n",
      "Epoch 207 train loss: 0.3671, eval loss 0.6959445476531982\n",
      "tensor([[0.1062],\n",
      "        [0.7311],\n",
      "        [0.7103],\n",
      "        ...,\n",
      "        [0.0388],\n",
      "        [0.0080],\n",
      "        [0.0759]])\n",
      "Epoch 208 train loss: 0.3588, eval loss 0.6958844065666199\n",
      "tensor([[0.1059],\n",
      "        [0.7312],\n",
      "        [0.7104],\n",
      "        ...,\n",
      "        [0.0388],\n",
      "        [0.0080],\n",
      "        [0.0760]])\n",
      "Epoch 209 train loss: 0.3917, eval loss 0.6958373188972473\n",
      "tensor([[0.1058],\n",
      "        [0.7317],\n",
      "        [0.7109],\n",
      "        ...,\n",
      "        [0.0389],\n",
      "        [0.0080],\n",
      "        [0.0762]])\n",
      "Epoch 210 train loss: 0.3673, eval loss 0.6958572864532471\n",
      "tensor([[0.1055],\n",
      "        [0.7322],\n",
      "        [0.7114],\n",
      "        ...,\n",
      "        [0.0389],\n",
      "        [0.0080],\n",
      "        [0.0762]])\n",
      "Epoch 211 train loss: 0.4276, eval loss 0.6958150267601013\n",
      "tensor([[0.1051],\n",
      "        [0.7328],\n",
      "        [0.7119],\n",
      "        ...,\n",
      "        [0.0388],\n",
      "        [0.0079],\n",
      "        [0.0761]])\n",
      "Epoch 212 train loss: 0.3803, eval loss 0.6957643032073975\n",
      "tensor([[0.1047],\n",
      "        [0.7333],\n",
      "        [0.7124],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0079],\n",
      "        [0.0760]])\n",
      "Epoch 213 train loss: 0.3735, eval loss 0.6957003474235535\n",
      "tensor([[0.1043],\n",
      "        [0.7336],\n",
      "        [0.7127],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0079],\n",
      "        [0.0759]])\n",
      "Epoch 214 train loss: 0.3542, eval loss 0.695655107498169\n",
      "tensor([[0.1044],\n",
      "        [0.7342],\n",
      "        [0.7134],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0079],\n",
      "        [0.0761]])\n",
      "Epoch 215 train loss: 0.3770, eval loss 0.6956815719604492\n",
      "tensor([[0.1041],\n",
      "        [0.7344],\n",
      "        [0.7137],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0079],\n",
      "        [0.0761]])\n",
      "Epoch 216 train loss: 0.3589, eval loss 0.6956537961959839\n",
      "tensor([[0.1036],\n",
      "        [0.7349],\n",
      "        [0.7141],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0078],\n",
      "        [0.0760]])\n",
      "Epoch 217 train loss: 0.3694, eval loss 0.6955839991569519\n",
      "tensor([[0.1030],\n",
      "        [0.7350],\n",
      "        [0.7143],\n",
      "        ...,\n",
      "        [0.0386],\n",
      "        [0.0078],\n",
      "        [0.0759]])\n",
      "Epoch 218 train loss: 0.3727, eval loss 0.6955003142356873\n",
      "tensor([[0.1029],\n",
      "        [0.7354],\n",
      "        [0.7148],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0078],\n",
      "        [0.0760]])\n",
      "Epoch 219 train loss: 0.3846, eval loss 0.695478618144989\n",
      "tensor([[0.1023],\n",
      "        [0.7354],\n",
      "        [0.7148],\n",
      "        ...,\n",
      "        [0.0385],\n",
      "        [0.0077],\n",
      "        [0.0757]])\n",
      "Epoch 220 train loss: 0.3687, eval loss 0.6953776478767395\n",
      "tensor([[0.1021],\n",
      "        [0.7360],\n",
      "        [0.7152],\n",
      "        ...,\n",
      "        [0.0386],\n",
      "        [0.0077],\n",
      "        [0.0758]])\n",
      "Epoch 221 train loss: 0.3567, eval loss 0.6953621506690979\n",
      "tensor([[0.1016],\n",
      "        [0.7365],\n",
      "        [0.7156],\n",
      "        ...,\n",
      "        [0.0386],\n",
      "        [0.0077],\n",
      "        [0.0757]])\n",
      "Epoch 222 train loss: 0.4007, eval loss 0.6953252553939819\n",
      "tensor([[0.1012],\n",
      "        [0.7367],\n",
      "        [0.7158],\n",
      "        ...,\n",
      "        [0.0387],\n",
      "        [0.0077],\n",
      "        [0.0758]])\n",
      "Epoch 223 train loss: 0.3525, eval loss 0.6952911615371704\n",
      "tensor([[0.1005],\n",
      "        [0.7370],\n",
      "        [0.7160],\n",
      "        ...,\n",
      "        [0.0385],\n",
      "        [0.0076],\n",
      "        [0.0755]])\n",
      "Epoch 224 train loss: 0.3817, eval loss 0.695173978805542\n",
      "tensor([[0.1003],\n",
      "        [0.7376],\n",
      "        [0.7167],\n",
      "        ...,\n",
      "        [0.0385],\n",
      "        [0.0076],\n",
      "        [0.0756]])\n",
      "Epoch 225 train loss: 0.3927, eval loss 0.6951636672019958\n",
      "tensor([[0.0998],\n",
      "        [0.7382],\n",
      "        [0.7172],\n",
      "        ...,\n",
      "        [0.0384],\n",
      "        [0.0076],\n",
      "        [0.0754]])\n",
      "Epoch 226 train loss: 0.3417, eval loss 0.6951053738594055\n",
      "tensor([[0.0996],\n",
      "        [0.7386],\n",
      "        [0.7176],\n",
      "        ...,\n",
      "        [0.0385],\n",
      "        [0.0075],\n",
      "        [0.0756]])\n",
      "Epoch 227 train loss: 0.3876, eval loss 0.6950938701629639\n",
      "tensor([[0.0992],\n",
      "        [0.7388],\n",
      "        [0.7177],\n",
      "        ...,\n",
      "        [0.0384],\n",
      "        [0.0075],\n",
      "        [0.0756]])\n",
      "Epoch 228 train loss: 0.3876, eval loss 0.6950372457504272\n",
      "tensor([[0.0989],\n",
      "        [0.7388],\n",
      "        [0.7177],\n",
      "        ...,\n",
      "        [0.0385],\n",
      "        [0.0075],\n",
      "        [0.0757]])\n",
      "Epoch 229 train loss: 0.3929, eval loss 0.6950253248214722\n",
      "tensor([[0.0987],\n",
      "        [0.7393],\n",
      "        [0.7183],\n",
      "        ...,\n",
      "        [0.0384],\n",
      "        [0.0075],\n",
      "        [0.0756]])\n",
      "Epoch 230 train loss: 0.3416, eval loss 0.6949668526649475\n",
      "tensor([[0.0981],\n",
      "        [0.7395],\n",
      "        [0.7185],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0074],\n",
      "        [0.0755]])\n",
      "Epoch 231 train loss: 0.3547, eval loss 0.6948820352554321\n",
      "tensor([[0.0975],\n",
      "        [0.7395],\n",
      "        [0.7184],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0074],\n",
      "        [0.0753]])\n",
      "Epoch 232 train loss: 0.3680, eval loss 0.6947929859161377\n",
      "tensor([[0.0974],\n",
      "        [0.7401],\n",
      "        [0.7191],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0074],\n",
      "        [0.0754]])\n",
      "Epoch 233 train loss: 0.4089, eval loss 0.6948103904724121\n",
      "tensor([[0.0972],\n",
      "        [0.7408],\n",
      "        [0.7197],\n",
      "        ...,\n",
      "        [0.0384],\n",
      "        [0.0074],\n",
      "        [0.0755]])\n",
      "Epoch 234 train loss: 0.3779, eval loss 0.6948179006576538\n",
      "tensor([[0.0966],\n",
      "        [0.7408],\n",
      "        [0.7197],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0073],\n",
      "        [0.0752]])\n",
      "Epoch 235 train loss: 0.3703, eval loss 0.6946969628334045\n",
      "tensor([[0.0964],\n",
      "        [0.7411],\n",
      "        [0.7200],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0073],\n",
      "        [0.0753]])\n",
      "Epoch 236 train loss: 0.3660, eval loss 0.6946870684623718\n",
      "tensor([[0.0961],\n",
      "        [0.7416],\n",
      "        [0.7206],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0073],\n",
      "        [0.0753]])\n",
      "Epoch 237 train loss: 0.3971, eval loss 0.6946642398834229\n",
      "tensor([[0.0959],\n",
      "        [0.7420],\n",
      "        [0.7209],\n",
      "        ...,\n",
      "        [0.0384],\n",
      "        [0.0073],\n",
      "        [0.0753]])\n",
      "Epoch 238 train loss: 0.3655, eval loss 0.6946498155593872\n",
      "tensor([[0.0955],\n",
      "        [0.7424],\n",
      "        [0.7212],\n",
      "        ...,\n",
      "        [0.0383],\n",
      "        [0.0072],\n",
      "        [0.0753]])\n",
      "Epoch 239 train loss: 0.3527, eval loss 0.6946097016334534\n",
      "tensor([[0.0950],\n",
      "        [0.7427],\n",
      "        [0.7215],\n",
      "        ...,\n",
      "        [0.0381],\n",
      "        [0.0072],\n",
      "        [0.0751]])\n",
      "Epoch 240 train loss: 0.3954, eval loss 0.6945368051528931\n",
      "tensor([[0.0950],\n",
      "        [0.7432],\n",
      "        [0.7220],\n",
      "        ...,\n",
      "        [0.0382],\n",
      "        [0.0072],\n",
      "        [0.0752]])\n",
      "Epoch 241 train loss: 0.3906, eval loss 0.6945779919624329\n",
      "tensor([[0.0946],\n",
      "        [0.7436],\n",
      "        [0.7222],\n",
      "        ...,\n",
      "        [0.0381],\n",
      "        [0.0072],\n",
      "        [0.0751]])\n",
      "Epoch 242 train loss: 0.3953, eval loss 0.6945196986198425\n",
      "tensor([[0.0942],\n",
      "        [0.7441],\n",
      "        [0.7227],\n",
      "        ...,\n",
      "        [0.0380],\n",
      "        [0.0071],\n",
      "        [0.0749]])\n",
      "Epoch 243 train loss: 0.3918, eval loss 0.6944491267204285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0937],\n",
      "        [0.7444],\n",
      "        [0.7228],\n",
      "        ...,\n",
      "        [0.0379],\n",
      "        [0.0071],\n",
      "        [0.0748]])\n",
      "Epoch 244 train loss: 0.3716, eval loss 0.6943768262863159\n",
      "tensor([[0.0935],\n",
      "        [0.7449],\n",
      "        [0.7234],\n",
      "        ...,\n",
      "        [0.0379],\n",
      "        [0.0071],\n",
      "        [0.0749]])\n",
      "Epoch 245 train loss: 0.3575, eval loss 0.6943439245223999\n",
      "tensor([[0.0931],\n",
      "        [0.7450],\n",
      "        [0.7235],\n",
      "        ...,\n",
      "        [0.0379],\n",
      "        [0.0070],\n",
      "        [0.0748]])\n",
      "Epoch 246 train loss: 0.3712, eval loss 0.6942840218544006\n",
      "tensor([[0.0928],\n",
      "        [0.7455],\n",
      "        [0.7240],\n",
      "        ...,\n",
      "        [0.0378],\n",
      "        [0.0070],\n",
      "        [0.0747]])\n",
      "Epoch 247 train loss: 0.3589, eval loss 0.6942514777183533\n",
      "tensor([[0.0923],\n",
      "        [0.7457],\n",
      "        [0.7242],\n",
      "        ...,\n",
      "        [0.0377],\n",
      "        [0.0070],\n",
      "        [0.0746]])\n",
      "Epoch 248 train loss: 0.3649, eval loss 0.6941948533058167\n",
      "tensor([[0.0921],\n",
      "        [0.7460],\n",
      "        [0.7244],\n",
      "        ...,\n",
      "        [0.0378],\n",
      "        [0.0070],\n",
      "        [0.0748]])\n",
      "Epoch 249 train loss: 0.3806, eval loss 0.6941985487937927\n",
      "tensor([[0.0917],\n",
      "        [0.7462],\n",
      "        [0.7246],\n",
      "        ...,\n",
      "        [0.0378],\n",
      "        [0.0070],\n",
      "        [0.0747]])\n",
      "Epoch 250 train loss: 0.3582, eval loss 0.6941416263580322\n",
      "tensor([[0.0913],\n",
      "        [0.7466],\n",
      "        [0.7250],\n",
      "        ...,\n",
      "        [0.0377],\n",
      "        [0.0069],\n",
      "        [0.0746]])\n",
      "Epoch 251 train loss: 0.3697, eval loss 0.6940831542015076\n",
      "tensor([[0.0909],\n",
      "        [0.7467],\n",
      "        [0.7250],\n",
      "        ...,\n",
      "        [0.0376],\n",
      "        [0.0069],\n",
      "        [0.0745]])\n",
      "Epoch 252 train loss: 0.3361, eval loss 0.6940471529960632\n",
      "tensor([[0.0908],\n",
      "        [0.7472],\n",
      "        [0.7255],\n",
      "        ...,\n",
      "        [0.0377],\n",
      "        [0.0069],\n",
      "        [0.0746]])\n",
      "Epoch 253 train loss: 0.3317, eval loss 0.6940406560897827\n",
      "tensor([[0.0906],\n",
      "        [0.7474],\n",
      "        [0.7256],\n",
      "        ...,\n",
      "        [0.0376],\n",
      "        [0.0069],\n",
      "        [0.0746]])\n",
      "Epoch 254 train loss: 0.3674, eval loss 0.6940025687217712\n",
      "tensor([[0.0906],\n",
      "        [0.7477],\n",
      "        [0.7260],\n",
      "        ...,\n",
      "        [0.0377],\n",
      "        [0.0069],\n",
      "        [0.0749]])\n",
      "Epoch 255 train loss: 0.3387, eval loss 0.694044291973114\n",
      "tensor([[0.0903],\n",
      "        [0.7478],\n",
      "        [0.7261],\n",
      "        ...,\n",
      "        [0.0377],\n",
      "        [0.0069],\n",
      "        [0.0749]])\n",
      "Epoch 256 train loss: 0.3942, eval loss 0.6940003037452698\n",
      "tensor([[0.0897],\n",
      "        [0.7478],\n",
      "        [0.7261],\n",
      "        ...,\n",
      "        [0.0375],\n",
      "        [0.0068],\n",
      "        [0.0746]])\n",
      "Epoch 257 train loss: 0.3576, eval loss 0.693896472454071\n",
      "tensor([[0.0895],\n",
      "        [0.7480],\n",
      "        [0.7263],\n",
      "        ...,\n",
      "        [0.0375],\n",
      "        [0.0068],\n",
      "        [0.0746]])\n",
      "Epoch 258 train loss: 0.3605, eval loss 0.6938784718513489\n",
      "tensor([[0.0894],\n",
      "        [0.7483],\n",
      "        [0.7268],\n",
      "        ...,\n",
      "        [0.0375],\n",
      "        [0.0068],\n",
      "        [0.0748]])\n",
      "Epoch 259 train loss: 0.3909, eval loss 0.6938769221305847\n",
      "tensor([[0.0891],\n",
      "        [0.7485],\n",
      "        [0.7270],\n",
      "        ...,\n",
      "        [0.0375],\n",
      "        [0.0068],\n",
      "        [0.0747]])\n",
      "Epoch 260 train loss: 0.3735, eval loss 0.6938338279724121\n",
      "tensor([[0.0886],\n",
      "        [0.7487],\n",
      "        [0.7269],\n",
      "        ...,\n",
      "        [0.0374],\n",
      "        [0.0068],\n",
      "        [0.0746]])\n",
      "Epoch 261 train loss: 0.3633, eval loss 0.6937581896781921\n",
      "tensor([[0.0881],\n",
      "        [0.7489],\n",
      "        [0.7269],\n",
      "        ...,\n",
      "        [0.0374],\n",
      "        [0.0067],\n",
      "        [0.0745]])\n",
      "Epoch 262 train loss: 0.3937, eval loss 0.6936855912208557\n",
      "tensor([[0.0877],\n",
      "        [0.7494],\n",
      "        [0.7273],\n",
      "        ...,\n",
      "        [0.0373],\n",
      "        [0.0067],\n",
      "        [0.0744]])\n",
      "Epoch 263 train loss: 0.3700, eval loss 0.6936304569244385\n",
      "tensor([[0.0876],\n",
      "        [0.7499],\n",
      "        [0.7278],\n",
      "        ...,\n",
      "        [0.0374],\n",
      "        [0.0067],\n",
      "        [0.0746]])\n",
      "Epoch 264 train loss: 0.4199, eval loss 0.6936624050140381\n",
      "tensor([[0.0873],\n",
      "        [0.7501],\n",
      "        [0.7280],\n",
      "        ...,\n",
      "        [0.0374],\n",
      "        [0.0067],\n",
      "        [0.0746]])\n",
      "Epoch 265 train loss: 0.3920, eval loss 0.6936357617378235\n",
      "tensor([[0.0872],\n",
      "        [0.7504],\n",
      "        [0.7283],\n",
      "        ...,\n",
      "        [0.0375],\n",
      "        [0.0067],\n",
      "        [0.0748]])\n",
      "Epoch 266 train loss: 0.3610, eval loss 0.6936437487602234\n",
      "tensor([[0.0872],\n",
      "        [0.7508],\n",
      "        [0.7287],\n",
      "        ...,\n",
      "        [0.0375],\n",
      "        [0.0067],\n",
      "        [0.0749]])\n"
     ]
    }
   ],
   "source": [
    "model = RegularizedMLP(input_size=X_train.shape[1], dropout_p=dropout_p)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "steps_without_improvement = 0\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "for epoch_num in range(max_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # note that we are using DataLoader to get batches\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        y_batch_pred = model(X_batch)\n",
    "        loss = loss_fn(y_batch_pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # model evaluation, early stopping\n",
    "    model.eval()\n",
    "    valid_metrics = evaluate_model(model, X_valid, y_valid, loss_fn)\n",
    "    if valid_metrics[\"loss\"] < best_val_loss:\n",
    "        best_val_loss = valid_metrics[\"loss\"]\n",
    "        steps_without_improvement = 0\n",
    "        best_model = deepcopy(model)\n",
    "        best_threshold = valid_metrics[\"optimal_threshold\"]\n",
    "    else:\n",
    "        steps_without_improvement += 1\n",
    "        if steps_without_improvement == early_stopping_patience:\n",
    "            break\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch_num} train loss: {loss.item():.4f}, eval loss {valid_metrics['loss']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4076],\n",
      "        [0.0196],\n",
      "        [0.0691],\n",
      "        ...,\n",
      "        [0.0043],\n",
      "        [0.4391],\n",
      "        [0.8711]])\n",
      "AUROC: 90.05%\n",
      "F1: 68.09%\n",
      "Precision: 60.84%\n",
      "Recall: 77.30%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_model, X_test, y_test, loss_fn, best_threshold)\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")\n",
    "print(f\"Precision: {100 * test_metrics['precision']:.2f}%\")\n",
    "print(f\"Recall: {100 * test_metrics['recall']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki wyglądają już dużo lepiej.\n",
    "\n",
    "Na koniec laboratorium dołożymy do naszego modelu jeszcze 3 powrzechnie używane techniki, które są bardzo proste, a pozwalają często ulepszyć wynik modelu.\n",
    "\n",
    "Pierwszą z nich są **warstwy normalizacji (normalization layers)**. Powstały one początkowo z założeniem, że przez przekształcenia przestrzeni dokonywane przez sieć zmienia się rozkład prawdopodobieństw pomiędzy warstwami, czyli tzw. *internal covariate shift*. Później okazało się, że zastosowanie takiej normalizacji wygładza powierzchnię funkcji kosztu, co ułatwia i przyspiesza optymalizację. Najpowszechniej używaną normalizacją jest **batch normalization (batch norm)**.\n",
    "\n",
    "Drugim ulepszeniem jest dodanie **wag klas (class weights)**. Mamy do czynienia z problemem klasyfikacji niezbalansowanej, więc klasa mniejszościowa, ważniejsza dla nas, powinna dostać większą wagę. Implementuje się to trywialnie prosto - po prostu mnożymy wartość funkcji kosztu dla danego przykładu przez wagę dla prawdziwej klasy tego przykładu. Praktycznie każdy klasyfikator operujący na jakiejś ważonej funkcji może działać w ten sposób, nie tylko sieci neuronowe.\n",
    "\n",
    "Ostatnim ulepszeniem jest zamiana SGD na optymalizator Adam, a konkretnie na optymalizator `AdamW`. Jest to przykład **optymalizatora adaptacyjnego (adaptive optimizer)**, który potrafi zaadaptować stałą uczącą dla każdego parametru z osobna w trakcie treningu. Wykorzystuje do tego gradienty - w uproszczeniu, im większa wariancja gradientu, tym mniejsze kroki w tym kierunku robimy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie 8 (1 punkt)\n",
    "\n",
    "Zaimplementuj model `NormalizingMLP`, o takiej samej strukturze jak `RegularizedMLP`, ale dodatkowo z warstwami `BatchNorm1d` pomiędzy warstwami `Linear` oraz `ReLU`.\n",
    "\n",
    "Za pomocą funkcji `compute_class_weight()` oblicz wagi dla poszczególnych klas. Użyj opcji `\"balanced\"`. Przekaż do funkcji kosztu wagę klasy pozytywnej (pamiętaj, aby zamienić ją na tensor).\n",
    "\n",
    "Zamień używany optymalizator na `AdamW`.\n",
    "\n",
    "Na koniec skopiuj resztę kodu do treningu z poprzedniego zadania, wytrenuj sieć i oblicz wyniki na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingMLP(nn.Module):\n",
    "    def __init__(self, input_size: int, dropout_p: float = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return sigmoid(self(x))\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred_score = self.predict_proba(x)\n",
    "        return torch.argmax(y_pred_score, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "dropout_p = 0.5\n",
    "l2_reg = 1e-4\n",
    "batch_size = 128\n",
    "max_epochs = 300\n",
    "\n",
    "early_stopping_patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1610],\n",
      "        [0.8710],\n",
      "        [0.8446],\n",
      "        ...,\n",
      "        [0.0805],\n",
      "        [0.0076],\n",
      "        [0.2642]])\n",
      "Epoch 0 train loss: 0.5841, eval loss 0.8223356604576111\n",
      "tensor([[0.0966],\n",
      "        [0.8658],\n",
      "        [0.8364],\n",
      "        ...,\n",
      "        [0.0535],\n",
      "        [0.0034],\n",
      "        [0.2193]])\n",
      "Epoch 1 train loss: 0.5024, eval loss 0.818015992641449\n",
      "tensor([[0.0848],\n",
      "        [0.8623],\n",
      "        [0.8395],\n",
      "        ...,\n",
      "        [0.0540],\n",
      "        [0.0023],\n",
      "        [0.2339]])\n",
      "Epoch 2 train loss: 0.5131, eval loss 0.8147842288017273\n",
      "tensor([[0.0720],\n",
      "        [0.8671],\n",
      "        [0.8412],\n",
      "        ...,\n",
      "        [0.0487],\n",
      "        [0.0022],\n",
      "        [0.2492]])\n",
      "Epoch 3 train loss: 0.5698, eval loss 0.8145799040794373\n",
      "tensor([[0.0701],\n",
      "        [0.8613],\n",
      "        [0.8327],\n",
      "        ...,\n",
      "        [0.0386],\n",
      "        [0.0022],\n",
      "        [0.2130]])\n",
      "Epoch 4 train loss: 0.5313, eval loss 0.8133034706115723\n",
      "tensor([[0.0680],\n",
      "        [0.8701],\n",
      "        [0.8402],\n",
      "        ...,\n",
      "        [0.0437],\n",
      "        [0.0025],\n",
      "        [0.2281]])\n",
      "Epoch 5 train loss: 0.5578, eval loss 0.812455415725708\n",
      "tensor([[0.0665],\n",
      "        [0.8780],\n",
      "        [0.8357],\n",
      "        ...,\n",
      "        [0.0341],\n",
      "        [0.0020],\n",
      "        [0.2172]])\n",
      "Epoch 6 train loss: 0.5527, eval loss 0.811855673789978\n",
      "tensor([[0.0613],\n",
      "        [0.8700],\n",
      "        [0.8336],\n",
      "        ...,\n",
      "        [0.0349],\n",
      "        [0.0032],\n",
      "        [0.2068]])\n",
      "Epoch 7 train loss: 0.5397, eval loss 0.8111935257911682\n",
      "tensor([[0.0859],\n",
      "        [0.8721],\n",
      "        [0.8268],\n",
      "        ...,\n",
      "        [0.0240],\n",
      "        [0.0020],\n",
      "        [0.2397]])\n",
      "Epoch 8 train loss: 0.5779, eval loss 0.8112012147903442\n",
      "tensor([[0.0739],\n",
      "        [0.8779],\n",
      "        [0.8353],\n",
      "        ...,\n",
      "        [0.0208],\n",
      "        [0.0014],\n",
      "        [0.2309]])\n",
      "Epoch 9 train loss: 0.5489, eval loss 0.810691773891449\n",
      "tensor([[0.0581],\n",
      "        [0.8680],\n",
      "        [0.8293],\n",
      "        ...,\n",
      "        [0.0218],\n",
      "        [0.0013],\n",
      "        [0.2529]])\n",
      "Epoch 10 train loss: 0.4993, eval loss 0.8103176355361938\n",
      "tensor([[0.0582],\n",
      "        [0.8725],\n",
      "        [0.8412],\n",
      "        ...,\n",
      "        [0.0194],\n",
      "        [0.0012],\n",
      "        [0.2592]])\n",
      "Epoch 11 train loss: 0.4814, eval loss 0.8107092976570129\n",
      "tensor([[0.0571],\n",
      "        [0.8772],\n",
      "        [0.8221],\n",
      "        ...,\n",
      "        [0.0141],\n",
      "        [0.0011],\n",
      "        [0.2452]])\n",
      "Epoch 12 train loss: 0.5176, eval loss 0.8101253509521484\n",
      "tensor([[6.5809e-02],\n",
      "        [8.8611e-01],\n",
      "        [8.3025e-01],\n",
      "        ...,\n",
      "        [1.4068e-02],\n",
      "        [5.7758e-04],\n",
      "        [2.3031e-01]])\n",
      "Epoch 13 train loss: 0.5144, eval loss 0.8101057410240173\n",
      "tensor([[0.0413],\n",
      "        [0.8908],\n",
      "        [0.8292],\n",
      "        ...,\n",
      "        [0.0189],\n",
      "        [0.0010],\n",
      "        [0.2356]])\n",
      "Epoch 14 train loss: 0.5690, eval loss 0.8102712631225586\n",
      "tensor([[4.1980e-02],\n",
      "        [8.8365e-01],\n",
      "        [8.3020e-01],\n",
      "        ...,\n",
      "        [1.8263e-02],\n",
      "        [8.5462e-04],\n",
      "        [2.4187e-01]])\n",
      "Epoch 15 train loss: 0.4666, eval loss 0.8095452785491943\n",
      "tensor([[4.9772e-02],\n",
      "        [8.8544e-01],\n",
      "        [8.1633e-01],\n",
      "        ...,\n",
      "        [1.5808e-02],\n",
      "        [6.4492e-04],\n",
      "        [2.9818e-01]])\n",
      "Epoch 16 train loss: 0.4527, eval loss 0.8093153238296509\n",
      "tensor([[5.9566e-02],\n",
      "        [8.8709e-01],\n",
      "        [8.2408e-01],\n",
      "        ...,\n",
      "        [1.3420e-02],\n",
      "        [4.4666e-04],\n",
      "        [2.5627e-01]])\n",
      "Epoch 17 train loss: 0.5340, eval loss 0.8088284134864807\n",
      "tensor([[4.8214e-02],\n",
      "        [8.8725e-01],\n",
      "        [8.1338e-01],\n",
      "        ...,\n",
      "        [1.6045e-02],\n",
      "        [4.5769e-04],\n",
      "        [2.4423e-01]])\n",
      "Epoch 18 train loss: 0.4856, eval loss 0.8088669180870056\n",
      "tensor([[5.5374e-02],\n",
      "        [8.8569e-01],\n",
      "        [8.2398e-01],\n",
      "        ...,\n",
      "        [1.0055e-02],\n",
      "        [4.7828e-04],\n",
      "        [2.6223e-01]])\n",
      "Epoch 19 train loss: 0.4783, eval loss 0.8081876635551453\n",
      "tensor([[5.1934e-02],\n",
      "        [8.9295e-01],\n",
      "        [8.1031e-01],\n",
      "        ...,\n",
      "        [8.7463e-03],\n",
      "        [3.6645e-04],\n",
      "        [2.8459e-01]])\n",
      "Epoch 20 train loss: 0.5044, eval loss 0.8085821270942688\n",
      "tensor([[5.1695e-02],\n",
      "        [8.8946e-01],\n",
      "        [8.2376e-01],\n",
      "        ...,\n",
      "        [1.1625e-02],\n",
      "        [5.4365e-04],\n",
      "        [3.1841e-01]])\n",
      "Epoch 21 train loss: 0.4976, eval loss 0.8082484602928162\n",
      "tensor([[6.8805e-02],\n",
      "        [8.9475e-01],\n",
      "        [8.1970e-01],\n",
      "        ...,\n",
      "        [6.1274e-03],\n",
      "        [1.8228e-04],\n",
      "        [2.8303e-01]])\n",
      "Epoch 22 train loss: 0.4993, eval loss 0.8084434270858765\n",
      "tensor([[4.1292e-02],\n",
      "        [8.9433e-01],\n",
      "        [8.1461e-01],\n",
      "        ...,\n",
      "        [7.1838e-03],\n",
      "        [2.9607e-04],\n",
      "        [3.1312e-01]])\n",
      "Epoch 23 train loss: 0.4685, eval loss 0.80796217918396\n",
      "tensor([[4.7565e-02],\n",
      "        [8.9107e-01],\n",
      "        [8.2047e-01],\n",
      "        ...,\n",
      "        [8.1902e-03],\n",
      "        [2.0175e-04],\n",
      "        [3.0329e-01]])\n",
      "Epoch 24 train loss: 0.5221, eval loss 0.8075583577156067\n",
      "tensor([[5.4296e-02],\n",
      "        [8.9888e-01],\n",
      "        [8.0615e-01],\n",
      "        ...,\n",
      "        [4.2975e-03],\n",
      "        [3.3686e-04],\n",
      "        [2.8602e-01]])\n",
      "Epoch 25 train loss: 0.4957, eval loss 0.8084162473678589\n",
      "tensor([[7.5885e-02],\n",
      "        [8.9883e-01],\n",
      "        [8.0935e-01],\n",
      "        ...,\n",
      "        [3.7949e-03],\n",
      "        [1.0520e-04],\n",
      "        [3.2377e-01]])\n",
      "Epoch 26 train loss: 0.4254, eval loss 0.808228611946106\n",
      "tensor([[4.1142e-02],\n",
      "        [9.0385e-01],\n",
      "        [8.1814e-01],\n",
      "        ...,\n",
      "        [6.3789e-03],\n",
      "        [2.7492e-04],\n",
      "        [2.7174e-01]])\n",
      "Epoch 27 train loss: 0.4842, eval loss 0.8088447451591492\n",
      "tensor([[4.9383e-02],\n",
      "        [8.9911e-01],\n",
      "        [8.1840e-01],\n",
      "        ...,\n",
      "        [3.3150e-03],\n",
      "        [1.3251e-04],\n",
      "        [3.4074e-01]])\n"
     ]
    }
   ],
   "source": [
    "model = NormalizingMLP(input_size=X_train.shape[1], dropout_p=dropout_p)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1])\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "steps_without_improvement = 0\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "for epoch_num in range(max_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # note that we are using DataLoader to get batches\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        y_batch_pred = model(X_batch)\n",
    "        loss = loss_fn(y_batch_pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # model evaluation, early stopping\n",
    "    model.eval()\n",
    "    valid_metrics = evaluate_model(model, X_valid, y_valid, loss_fn)\n",
    "    if valid_metrics[\"loss\"] < best_val_loss:\n",
    "        best_val_loss = valid_metrics[\"loss\"]\n",
    "        steps_without_improvement = 0\n",
    "        best_model = deepcopy(model)\n",
    "        best_threshold = valid_metrics[\"optimal_threshold\"]\n",
    "    else:\n",
    "        steps_without_improvement += 1\n",
    "        if steps_without_improvement == early_stopping_patience:\n",
    "            break\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch_num} train loss: {loss.item():.4f}, eval loss {valid_metrics['loss']}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.4469e-01],\n",
      "        [4.7431e-05],\n",
      "        [1.7914e-01],\n",
      "        ...,\n",
      "        [2.7743e-03],\n",
      "        [7.4897e-01],\n",
      "        [9.7270e-01]])\n",
      "AUROC: 90.58%\n",
      "F1: 69.30%\n",
      "Precision: 61.14%\n",
      "Recall: 79.97%\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(best_model, X_test, y_test, loss_fn, best_threshold)\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")\n",
    "print(f\"Precision: {100 * test_metrics['precision']:.2f}%\")\n",
    "print(f\"Recall: {100 * test_metrics['recall']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytania kontrolne (1 punkt)\n",
    "\n",
    "1. Wymień 4 najważniejsze twoim zdaniem hiperparametry sieci neuronowej.\n",
    "\n",
    "Architektura sieci: liczba warstw i neuronów w nich.\n",
    "Funkcja aktywacji.\n",
    "Learning rate.\n",
    "Dropout rate.\n",
    "\n",
    "2. Czy widzisz jakiś problem w użyciu regularyzacji L1 w treningu sieci neuronowych? Czy dropout może twoim zdaniem stanowić alternatywę dla tego rodzaju regularyzacji?\n",
    "\n",
    "L1 mocno promuje wagi równe zero, a L2 wagi zmierzające ku zeru.\n",
    "Uzyskanie dużej ilości wag równej 0 może by niekorzystne bo towrzy to martwe neurony. Dropout jest nieco innym rodzajem regularyzacji. Można go porównać bardziej do ensemble learningu, w pewien sposób za każdym razem szkolimy nieco inną sieć.\n",
    "\n",
    "3. Czy użycie innej metryki do wczesnego stopu da taki sam model końcowy? Czemu?\n",
    "\n",
    "Może dać inny model. Z inną metryką możemy zatrzymać uczenie w innym momencie co da inny rezultat końcowy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyoRnHT4GFR9"
   },
   "source": [
    "## Akceleracja sprzętowa (dla zainteresowanych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wcześniej wspominaliśmy, użycie akceleracji sprzętowej, czyli po prostu GPU do obliczeń, jest bardzo efektywne w przypadku sieci neuronowych. Karty graficzne bardzo efektywnie mnożą macierze, a sieci neuronowe to, jak można było się przekonać, dużo mnożenia macierzy.\n",
    "\n",
    "W PyTorchu jest to dosyć łatwe, ale trzeba robić to explicite. Służy do tego metoda `.to()`, która przenosi tensory między CPU i GPU. Poniżej przykład, jak to się robi (oczywiście trzeba mieć skonfigurowane GPU, żeby działało):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.9967, time: 0.021558046340942383\n",
      "Epoch 1 train loss: 0.4910, time: 0.462691068649292\n",
      "Epoch 2 train loss: 0.4931, time: 0.4397618770599365\n",
      "Epoch 3 train loss: 0.4165, time: 0.40818190574645996\n",
      "Epoch 4 train loss: 0.5879, time: 0.4182722568511963\n",
      "Epoch 6 train loss: 0.3052, time: 0.42516064643859863\n",
      "Epoch 7 train loss: 0.3984, time: 0.4813978672027588\n",
      "Epoch 8 train loss: 0.4517, time: 0.4550185203552246\n",
      "Epoch 9 train loss: 0.4239, time: 0.4588887691497803\n",
      "Epoch 11 train loss: 0.4695, time: 0.4519162178039551\n",
      "Epoch 12 train loss: 0.4071, time: 0.45142602920532227\n",
      "Epoch 13 train loss: 0.5055, time: 0.4342341423034668\n",
      "Epoch 14 train loss: 0.3865, time: 0.4416954517364502\n",
      "Epoch 15 train loss: 0.4245, time: 0.4435718059539795\n",
      "Epoch 17 train loss: 0.3426, time: 0.4612889289855957\n",
      "Epoch 18 train loss: 0.4367, time: 0.4729166030883789\n",
      "Epoch 19 train loss: 0.4512, time: 0.4845590591430664\n",
      "Epoch 20 train loss: 0.3940, time: 0.4803650379180908\n",
      "Epoch 22 train loss: 0.5124, time: 0.4645366668701172\n",
      "Epoch 23 train loss: 0.4160, time: 0.41678643226623535\n",
      "Epoch 24 train loss: 0.3974, time: 0.425203800201416\n",
      "Epoch 25 train loss: 0.4935, time: 0.44222044944763184\n",
      "Epoch 26 train loss: 0.4668, time: 0.44217753410339355\n",
      "Epoch 28 train loss: 0.5689, time: 0.4258110523223877\n",
      "Epoch 29 train loss: 0.4941, time: 0.4178807735443115\n",
      "tensor([[5.8242e-01],\n",
      "        [9.7694e-05],\n",
      "        [2.1165e-01],\n",
      "        ...,\n",
      "        [3.0859e-03],\n",
      "        [6.9019e-01],\n",
      "        [9.7390e-01]])\n",
      "AUROC: 90.58%\n",
      "F1: 69.30%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = NormalizingMLP(input_size=X_train.shape[1], dropout_p=dropout_p).to(\"cuda\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# note that we are using loss function with sigmoid built in\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(weights)[1].to(\"cuda\"))\n",
    "\n",
    "step_counter = 0\n",
    "time_from_eval = time.time()\n",
    "for epoch_id in range(30):\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x = batch_x.to(\"cuda\")\n",
    "        batch_y = batch_y.to(\"cuda\")\n",
    "\n",
    "        loss = loss_fn(model(batch_x), batch_y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step_counter % evaluation_steps == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch_id} train loss: {loss.item():.4f}, time: {time.time() - time_from_eval}\"\n",
    "            )\n",
    "            time_from_eval = time.time()\n",
    "\n",
    "        step_counter += 1\n",
    "\n",
    "test_res = evaluate_model(\n",
    "    model.to(\"cpu\"), X_test, y_test, loss_fn.to(\"cpu\"), threshold=0.5\n",
    ")\n",
    "\n",
    "print(f\"AUROC: {100 * test_metrics['AUROC']:.2f}%\")\n",
    "print(f\"F1: {100 * test_metrics['F1-score']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki mogą się różnić z modelem na CPU, zauważ o ile szybszy jest ten model w porównaniu z CPU (przynajmniej w przypadków scenariuszy tak będzie ;)).\n",
    "\n",
    "Dla zainteresowanych polecamy [tę serie artykułów](https://medium.com/@adi.fu7/ai-accelerators-part-i-intro-822c2cdb4ca4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie dla chętnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzieliśmy, sieci neuronowe mają bardzo dużo hiperparametrów. Przeszukiwanie ich grid search'em jest więc niewykonalne, a chociaż random search by działał, to potrzebowałby wielu iteracji, co też jest kosztowne obliczeniowo.\n",
    "\n",
    "Zaimplementuj inteligentne przeszukiwanie przestrzeni hiperparametrów za pomocą biblioteki [Optuna](https://optuna.org/). Implementuje ona między innymi algorytm Tree Parzen Estimator (TPE), należący do grupy algorytmów typu Bayesian search. Typowo osiągają one bardzo dobre wyniki, a właściwie zawsze lepsze od przeszukiwania losowego. Do tego wystarcza im często niewielka liczba kroków.\n",
    "\n",
    "Zaimplementuj 3-warstwową sieć MLP, gdzie pierwsza warstwa ma rozmiar ukryty N, a druga N // 2. Ucz ją optymalizatorem Adam przez maksymalnie 300 epok z cierpliwością 10.\n",
    "\n",
    "Przeszukaj wybrane zakresy dla hiperparametrów:\n",
    "- rozmiar warstw ukrytych (N)\n",
    "- stała ucząca\n",
    "- batch size\n",
    "- siła regularyzacji L2\n",
    "- prawdopodobieństwo dropoutu\n",
    "\n",
    "Wykorzystaj przynajmniej 30 iteracji. Następnie przełącz algorytm na losowy (Optuna także jego implementuje), wykonaj 30 iteracji i porównaj jakość wyników.\n",
    "\n",
    "Przydatne materiały:\n",
    "- [Optuna code examples - PyTorch](https://optuna.org/#code_examples)\n",
    "- [Auto-Tuning Hyperparameters with Optuna and PyTorch](https://www.youtube.com/watch?v=P6NwZVl8ttc)\n",
    "- [Hyperparameter Tuning of Neural Networks with Optuna and PyTorch](https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837)\n",
    "- [Using Optuna to Optimize PyTorch Hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "a5d7af91182035c53be6efb3f9b18ffc3e259c9c524705249407647c970de949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
